<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OneDeakin CloudDeakin Template</title>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css?version=202001061835" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <!-- prod -->
    <link rel="stylesheet" type="text/css" href="/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.css?v=20220329">
    <link rel="stylesheet" type="text/css" href="/content/deakin-embedded-comments/embeddedComments.css?v=20210208">
</head>

<body data-template-type="oneDeakin">
<div class="oneDeakin_instructions" style="font-size: 1rem; background: #e9ecef; padding: .4rem 1rem; border-radius: .3rem; margin-bottom: 1rem;">
<p><strong>OneDeakin template features</strong></p>
<blockquote>
<p>The OneDeakin template is full of features that help you advance the narrative and make learning and teaching happen.</p>
</blockquote>
<p>The CloudDeakin DLF Apps site contains information on all the template features, and how and when to use them. Accessing this site requires a simple two step process.</p>
<p><strong>Step 1:</strong> Use this form to be <a title="enrol in the CloudDeakin DLF Apps site" href="https://forms.office.com/r/0p7xpyMThG" target="blank">enrolled in the CloudDeakin DLF Apps site</a>.</p>
<p><strong>Step 2: </strong><span style="text-decoration: underline;">Only after you have enrolled in Step 1 above</span>, you can then access the <a title="access the CloudDeakin DLF Apps site" href="/d2l/home/1308183" target="blank">DLF Apps site</a> or search for 'DLF Apps' in the Sites Grid Menu.</p>
</div>
<div class="oneDeakin_instructions" style="font-size: 1rem; background: #e9ecef; padding: .4rem 1rem; border-radius: .3rem;">
<p><strong>OneDeakin Template Colours</strong></p>
<p>Define the OneDeakin Template colour by using the Heading3 'teal', 'turquoise', 'orange' or 'pink'.</p>
<p>When your page is published, this Heading3 will be removed from view. It it important that this first Heading3 remains in the OneDeakin template.</p>
</div>
<h3>teal</h3>
<h3>banner medium bus/inf/information-systems-10</h3>
<!-- CONTENT STARTS HERE -->
<h2>What is Responsible AI and do we really need it?</h2>
<p>The increasing use of AI has significant legal, ethical, societal, and economical implications for everyone. Concerns about how AI is used continue to rise with privacy breaches, bias in automated selection procedures, inappropriate generation of debt demands, and the dangerous behaviour of semi-autonomous vehicles. The influence of AI on jobs, people's well-being, healthcare, the distribution of wealth and other social considerations is unclear.</p>
<p>According to <a href="https://www.accenture.com/au-en/services/applied-intelligence/ai-ethics-governance#:~:text=Responsible%20AI%20is%20the%20practice,Artificial%20Intelligence" target="_blank" rel="noopener">Accenture (2022)</a> Responsible AI (RAI) &nbsp;refers to:</p>
<blockquote>
<p>the practice of designing, developing, and deploying AI with good intention to empower employees and businesses, and fairly impact customers and society—allowing companies to engender trust and scale AI with confidence.</p>
</blockquote>
<p>The need for responsible AI has arisen from a limited understanding of critical issues that emerged with the use and development of AI technologies. Recent studies and cases in practice have shown that AI can potentially create unintended consequences such as biases, discrimination, errors, unexpected results, and an overall lack of transparency regarding how outcomes are achieved. RAI is concerned with establishing ethical principles and human values to reduce biases, promote fairness and to ensure robustness and security in the use of AI technologies.</p>
<p>According to Salesforce’s chief ethical and humane use officer:</p>
<blockquote>
<p>Some of AI’s greatest failures to date have been the product of bias, whether it’s recruiting tools that favor men over women or facial recognition programs that misidentify people of color. Embedding ethics and inclusion in the design and delivery of AI not only helps to mitigate bias — it also helps to increase the accuracy and relevancy of our models, and to increase their performance in all kinds of situations once deployed.</p>
<p><em>Renieris et al’. (2022)</em></p>
</blockquote>
<p></p>
<p><img src="Images/2.3%20how_ai_systems_amplify_bias.jpg" alt="5 images of people cooking with AI showing gender bias labelling one man as a woman.This example of gender biased is adapted from a report published by researchers from the University of virginia. a visual semantic role labeling system has learned to identify a person cooking as female even when the image is male." title="5 images of people cooking with AI showing gender bias labelling one man as a woman. " width="808" height="495" style="display: block; margin-left: auto; margin-right: auto;"></p>
<p>Source: &nbsp;Pratt (2020)</p>
<p><a href="https://www.techtarget.com/searchenterpriseai/definition/responsible-AI" target="_blank" rel="noopener">Gillis (2021)</a> suggests including the qualities and principles listed in the figure below. We will discuss each of these elements as we progress through the trimester.&nbsp;</p>
<p><img src="Images/2.3%20Responsible%20AI.png" alt="Responsible AI figure, RAI in the centre with qualities and principles making it up feeding into it; explainable, monitorable, reproducible, secure, human-centered, unbiased and justifiable " title="Responsible AI figure, RAI in the centre with qualities and principles making it up feeding into it; explainable, monitorable, reproducible, secure, human-centered, unbiased and justifiable " width="485" height="470" style="display: block; margin-left: auto; margin-right: auto;"></p>
<p style="text-align: center;"><span style="font-size: 14px;">Qualities and principles of Responsible AI. Source: <a href="https://www.techtarget.com/searchenterpriseai/definition/responsible-AI" target="_blank" rel="noopener">Responsible AI</a></span></p>
<p>RAI is still a relatively new field that has rapidly developed over the past several years and has become a popular term in both business and the media. It’s designed to help us recognize, prepare for, and mitigate the potentially harmful effects of AI. As Dignum (2019) argues&nbsp;<br>RAI should not be only about ticking some ethical 'boxes' or the development of some add-on features in AI systems. It is a governance framework that documents how a specific organization is addressing the challenges around AI from both an ethical and legal point of view. Resolving ambiguity for where responsibility lies if something goes wrong is an important driver for responsible AI initiatives.</p>
<p></p>
<blockquote>
<p>Researchers, policymakers, industry and society at large, all are increasingly recognizing the need for design and engineering approaches that ensure the safe, beneficial and fair use of AI technologies, that consider the implications of ethically and legally relevant decision-making by machines, and that evaluate the ethical and legal status of AI.</p>
<p><em>Dignum., 2019, p. 48</em></p>
</blockquote>
<p>Responsible AI requires informed participation of all stakeholders with education at the forefront to enable an understanding of the effects on society. Perhaps what is needed is a code of conduct for both AI systems, and the people that create and use these systems, which leads to AI systems conforming to our ethical expectations.</p>
<p>Practitioners and researchers have called for AI regulation. Standards for accountability when AI technology has unintended consequences are in their infancy, for example the EU Artificial Intelligence Act (<a href="https://artificialintelligenceact.eu">The AI Act, 2022</a>). It is not unusual for machine learning algorithms to introduce bias when being trained with a particular dataset and thus its decision will be influenced by that bias. For example, Amazon's recruiting algorithm was trained on 10 years of data from the assessment of resumes by predominately male recruiters that turned out to have a bias against women. Hence the algorithm tended to reject female candidates (<a href="https://www.geeksforgeeks.org/5-algorithms-that-demonstrate-artificial-intelligence-bias/">GeeksforGeeks , July 2022</a>).</p>
<p>RAI should be a top management concern and many organisations now have established responsible AI teams and units to ensure that AI is developed and used appropriately. This illustrates an increasingly common view that as AI gains influence over business operations and organisations are required to address risks associated with this emerging technology, only a few organisations have prioritised responsible AI (RAI) program to address concerns regarding AI. The findings from the survey conducted by (<a href="https://sloanreview.mit.edu/article/should-organizations-link-responsible-ai-and-corporate-social-responsibility-its-complicated/" target="_blank" rel="noopener">Renieris et al., 2022</a>) show that only 52% (11 out of 21 AI experts) believe &nbsp;that firms have an RAI program in place, and the result would explain why there have been an increase in <a href="https://medium.com/syncedreview/2019-in-review-10-ai-failures-317b46155350" target="_blank" rel="noopener">AI failure cases</a>. According to the study, mature RAI programs will help to minimize AI system failures.&nbsp;</p>
<p></p>
<hr>
<p><!-- CONTENT ENDS HERE --></p>
<div><iframe src="/content/deakin-embedded-comments/embedded-comments-loader.html?v=20201006" style="position: absolute; left: -9999px; top: -9999px; width: 0px; height: 0px;"></iframe> <!--FORUMVARIABLESTART-->
<div style="display: none;" data-forumname="null"></div>
<!--FORUMVARIABLEEND--></div>
<div>
<script src="https://s.brightspace.com/lib/jquery/2.2.4/jquery.min.js?version=202001061835" integrity="sha384-rY/jv8mMhqDabXSo+UCggqKtdmBfd3qC2/KvyTDNQ6PcUJXaxK1tMepoQda4g5vB" crossorigin="anonymous"></script>
<!-- prod -->
<script src="/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.js?v=20220329"></script>
<script src="/content/deakinscripts/moment/moment.2.21.js"></script>
<script src="/content/deakin-embedded-comments/embeddedComments.js?v=20210208"></script>
<script>
if(navigator.onLine)console.log("online"),$(document).ready((function(){var e,t,n;-1<window.location.href.indexOf("https://d2l")?console.log("in CloudDeakin"):(console.log("not in CloudDeakin"),$("body").prepend('<div style="background:#990050;color:#FFFFFF;padding:1rem;text-align:center;"><p>You are viewing downloaded HTML content outside of CloudDeakin.<br>Some content, images, links, interactives etc. may not render or function as they do when they are viewed in CloudDeakin.</p></div>'),$.expr[":"].textEquals=$.expr[":"].textEquals||$.expr.createPseudo((function(e){return function(t){return $(t).text().match("^"+e+"$")}})),$("h3:textEquals('container'), h3:textEquals('Container'),  h3:textEquals('container callout'), h3:textEquals('Container callout'), h3:textEquals('container instructions'), h3:textEquals('Container instructions'), h3:textEquals('container colourbox'), h3:textEquals('Container colourbox'), h3:textEquals('container references'), h3:textEquals('Container references'), h3:textEquals('banner'), h3:textEquals('banner big'), h3:textEquals('banner medium'), h3:textEquals('banner small'), h3:textEquals('fullwidth'), h3:textEquals('floatright'), h3:textEquals('floatleft'), h3:textEquals('flipcard'), h3:textEquals('tabs'), h3:textEquals('grid'), h3:textEquals('accordion'), h3:textEquals('Accordion'), h3:textEquals('popup'), h3:textEquals('fluidvideo'), h3:textEquals('teal'), h3:textEquals('turquoise'), h3:textEquals('pink'), h3:textEquals('orange'), h3:textEquals('nikeri'), h4:textEquals('front'), h4:textEquals('back'), h4:textEquals('column'), h3:contains('banner'), hr, .oneDeakin_instructions").remove(),$("body").addClass("oneDeakin"),$("body").removeAttr("style"),$("body").css({'font-family':'"HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif','font-size':'16px','margin':'10px auto','max-width':'90%'}),n="<link rel='stylesheet' href='https://d2l.deakin.edu.au/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.css' type='text/css' media='screen'>",(t=(e=$("head")).find("link[rel='stylesheet']:last")).length?t.after(n):e.append(n))}));else{console.log("offline");var body=document.getElementsByTagName("body")[0],newDiv=document.createElement("div");newDiv.innerHTML='<p style="background:#990050;color:#FFFFFF;padding:1rem;text-align:center;width:100%;font-size:14px;">You are viewing downloaded HTML content outside of CloudDeakin without any internet connection.<br>Some content, images, links, interactives etc. may not render or function as they do when they are viewed in CloudDeakin.</p>',body.insertBefore(newDiv,body.firstChild);var h3_ele=document.querySelectorAll("h3");if(h3_ele.length)for(var i=0;i<h3_ele.length;i++)"teal"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"turquoise"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"pink"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"nikeri"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"orange"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container callout"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container callout"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container instructions"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container instructions"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container colourbox"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container colourbox"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container references"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container references"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner big"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner medium"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner small"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"fullwidth"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"floatright"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"floatleft"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"flipcard"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"tabs"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"grid"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"accordion"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Accordion"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"popup"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"fluidvideo"==h3_ele[i].textContent&&(h3_ele[i].style.display="none");var h4_ele=document.querySelectorAll("h4");if(h4_ele.length)for(i=0;i<h4_ele.length;i++)"front"==h4_ele[i].textContent&&(h4_ele[i].style.display="none"),"back"==h4_ele[i].textContent&&(h4_ele[i].style.display="none"),"column"==h4_ele[i].textContent&&(h4_ele[i].style.display="none");var instr_ele=document.getElementsByClassName("oneDeakin_instructions");for(i=0;i<instr_ele.length;++i)(item=instr_ele[i]).style.display="none";var hr_ele=document.getElementsByTagName("hr");for(i=0;i<hr_ele.length;++i)(item=hr_ele[i]).style.display="none"}
</script>
</div>
<div style="position: static !important;"></div>
<div style="position: static !important;"></div>
<div style="position: static !important;"></div>
</body></html>