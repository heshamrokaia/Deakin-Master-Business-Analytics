<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OneDeakin CloudDeakin Template</title>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css?version=202001061835" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <!-- prod -->
    <link rel="stylesheet" type="text/css" href="/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.css?v=20220329">
    <link rel="stylesheet" type="text/css" href="/content/deakin-embedded-comments/embeddedComments.css?v=20210208">
</head><body data-template-type="oneDeakin"><div class="oneDeakin_instructions" style="font-size: 1rem; background: #e9ecef; padding: .4rem 1rem; border-radius: .3rem; margin-bottom: 1rem;">
<p><strong>OneDeakin template features</strong></p>
<blockquote>
<p>The OneDeakin template is full of features that help you advance the narrative and make learning and teaching happen.</p>
</blockquote>
<p>The CloudDeakin DLF Apps site contains information on all the template features, and how and when to use them. Accessing this site requires a simple two step process.</p>
<p><strong>Step 1:</strong> Use this form to be <a title="enrol in the CloudDeakin DLF Apps site" href="https://forms.office.com/r/0p7xpyMThG" target="blank">enrolled in the CloudDeakin DLF Apps site</a>.</p>
<p><strong>Step 2: </strong><span style="text-decoration: underline;">Only after you have enrolled in Step 1 above</span>, you can then access the <a title="access the CloudDeakin DLF Apps site" href="/d2l/home/1308183" target="blank">DLF Apps site</a> or search for 'DLF Apps' in the Sites Grid Menu.</p>
</div>
<div class="oneDeakin_instructions" style="font-size: 1rem; background: #e9ecef; padding: .4rem 1rem; border-radius: .3rem;">
<p><strong>OneDeakin Template Colours</strong></p>
<p>Define the OneDeakin Template colour by using the Heading3 'teal', 'turquoise', 'orange' or 'pink'.</p>
<p>When your page is published, this Heading3 will be removed from view. It it important that this first Heading3 remains in the OneDeakin template.</p>
</div>
<h3>teal</h3>
<h3>banner medium IT/ain/Ai-13</h3>
<!-- CONTENT STARTS HERE -->
<h2>Fairness, equity, and discrimination in automated decision making</h2>
<p>The advancement of technology and automation promises to transform how we approach business, finance, medicine, media, operations, and more. Automated decision-making systems (ADMs) are increasingly commonplace in fields like criminal justice, healthcare diagnosis and treatment, human resource management, social work, credit, and insurance (Alejandro Noriega-Camperoet et all, 2019). However, worries are also growing that this neutral technology could lead to a new source of unwanted discrimination against racial or other vulnerable and/or legally protected disadvantaged populations (Kuppler. et all, 2021, Jillson, E., 2021). As a result, significant work on defining and improving for algorithmic fairness has increased in recent years. Therefore, in recent years, a great deal of research has been done to formalise conceptions of justice such as fairness, equity and discrimination into metrics that might identify and reduce bias and injustice in automated decision making.&nbsp;</p>
<h3>Fairness</h3>
<p>Given that such autonomous systems can cause severe harm to individuals and social groups, fairness concerns have also arisen. One of the main reasons for discrimination or bias in algorithmic decision-making is the quality of historical input data, because algorithms learn from these input data as an example; thus, the learning process depends on the exposed examples. If algorithms are trained on erroneous, biased or unrepresentative input data, they will create discriminatory or biased results. As a result, if algorithms' input (or training) data are biased, they may make or reproduce biased decisions. &nbsp;For example, an algorithm developed for benign purposes like healthcare resource allocation and advertising actually resulted in racial bias. Again, if an algorithm such as hiring decision was built with data that lacked racial or gender diversity, the result may be deception and discrimination.&nbsp;</p>
<h3>Representation Bias</h3>
<p>Representation bias is another form of bias related to algorithms. This is related to the input data, where there is either a lack of information from specific groups or characteristics or and over representation of this information (Köchling &amp; Wehner, 2020). &nbsp;For example, representation bias might occur if females in comparison to males are underrepresented in the training data of an algorithm. Consequently, the outcome could be in favour of the overrepresented group (i.e., males) and, therefore, lead to discriminatory outcomes in relation to the underrepresented group (Female). As a well-known example "stemming from the current debate around transparency, bias, and fairness in algorithmic decision making is the hiring algorithms applied by the American e-commerce specialist. Amazon yielded an extreme disadvantage of female applicants, which finally led Amazon to shut down the complete algorithmic decision-making for their hiring decision" (Köchling &amp; Wehner, 2020, p. 796).&nbsp;</p>
<h3>container callout</h3>
<h3>Consider</h3>
<p>Think about an algorithm that allows a company to target consumers most interested in buying their product. This seems like a straightforward benefit, doesn’t it? What if the model also pinpoints those consumers by considering race, colour, religion, and gender and the result is digital redlining.</p>
<hr>
<p>Any algorithm or model that causes more harm than or is likely to cause substantial injury to consumers that is not reasonably avoidable by consumers and not outweighed by countervailing benefits to consumers or to competition can be classified as unfair.</p>
<p>Therefore, it’s very important to expand our data set from the beginning, incorporate data gaps into model's architecture, and, in light of any flaws, impose limitations whether or how the model is used. It’s also essential to test our algorithms, both before use and periodically after that to make sure that it doesn’t discriminate on the basis of race, gender, or other protected class (Jillson, E., 2021).&nbsp;</p>
<h3>Activity</h3>
<h3>container colourbox</h3>
<h3><em class="fa fa-eye" style="font-size: 24px;"></em><strong style="font-size: 1em;">&nbsp;Watch</strong></h3>
<p>Let’s expand a bit more on this issue of ethics, bias and fairness in automation. In the following video Professor Emily Hand explores this specially in relation to machine learning. The concepts she describes are valid for other types of automation as well.</p>
<p><strong><em class="fa fa-info-circle" style="font-size: 24px;"></em></strong><span style="font-size: 1em;">&nbsp;Watch the video below and take note of anything that you disagree with or find confusing. Bring that to this weeks lecture to explore with others in class.</span></p>
<hr>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/hXSSmF-6Yzs?wmode=opaque&amp;rel=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen" style="margin: 0 auto; display: block;"></iframe></p>
<p></p>
<hr>
<p><!-- CONTENT ENDS HERE --></p>
<div><iframe src="/content/deakin-embedded-comments/embedded-comments-loader.html?v=20201006" style="position: absolute; left: -9999px; top: -9999px; width: 0px; height: 0px;"></iframe> <!--FORUMVARIABLESTART-->
<div style="display: none;" data-forumname="null"></div>
<!--FORUMVARIABLEEND--></div>
<div>
<script src="https://s.brightspace.com/lib/jquery/2.2.4/jquery.min.js?version=202001061835" integrity="sha384-rY/jv8mMhqDabXSo+UCggqKtdmBfd3qC2/KvyTDNQ6PcUJXaxK1tMepoQda4g5vB" crossorigin="anonymous"></script>
<!-- prod -->
<script src="/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.js?v=20220329"></script>
<script src="/content/deakinscripts/moment/moment.2.21.js"></script>
<script src="/content/deakin-embedded-comments/embeddedComments.js?v=20210208"></script>
<script>
if(navigator.onLine)console.log("online"),$(document).ready((function(){var e,t,n;-1<window.location.href.indexOf("https://d2l")?console.log("in CloudDeakin"):(console.log("not in CloudDeakin"),$("body").prepend('<div style="background:#990050;color:#FFFFFF;padding:1rem;text-align:center;"><p>You are viewing downloaded HTML content outside of CloudDeakin.<br>Some content, images, links, interactives etc. may not render or function as they do when they are viewed in CloudDeakin.</p></div>'),$.expr[":"].textEquals=$.expr[":"].textEquals||$.expr.createPseudo((function(e){return function(t){return $(t).text().match("^"+e+"$")}})),$("h3:textEquals('container'), h3:textEquals('Container'),  h3:textEquals('container callout'), h3:textEquals('Container callout'), h3:textEquals('container instructions'), h3:textEquals('Container instructions'), h3:textEquals('container colourbox'), h3:textEquals('Container colourbox'), h3:textEquals('container references'), h3:textEquals('Container references'), h3:textEquals('banner'), h3:textEquals('banner big'), h3:textEquals('banner medium'), h3:textEquals('banner small'), h3:textEquals('fullwidth'), h3:textEquals('floatright'), h3:textEquals('floatleft'), h3:textEquals('flipcard'), h3:textEquals('tabs'), h3:textEquals('grid'), h3:textEquals('accordion'), h3:textEquals('Accordion'), h3:textEquals('popup'), h3:textEquals('fluidvideo'), h3:textEquals('teal'), h3:textEquals('turquoise'), h3:textEquals('pink'), h3:textEquals('orange'), h3:textEquals('nikeri'), h4:textEquals('front'), h4:textEquals('back'), h4:textEquals('column'), h3:contains('banner'), hr, .oneDeakin_instructions").remove(),$("body").addClass("oneDeakin"),$("body").removeAttr("style"),$("body").css({'font-family':'"HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif','font-size':'16px','margin':'10px auto','max-width':'90%'}),n="<link rel='stylesheet' href='https://d2l.deakin.edu.au/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.css' type='text/css' media='screen'>",(t=(e=$("head")).find("link[rel='stylesheet']:last")).length?t.after(n):e.append(n))}));else{console.log("offline");var body=document.getElementsByTagName("body")[0],newDiv=document.createElement("div");newDiv.innerHTML='<p style="background:#990050;color:#FFFFFF;padding:1rem;text-align:center;width:100%;font-size:14px;">You are viewing downloaded HTML content outside of CloudDeakin without any internet connection.<br>Some content, images, links, interactives etc. may not render or function as they do when they are viewed in CloudDeakin.</p>',body.insertBefore(newDiv,body.firstChild);var h3_ele=document.querySelectorAll("h3");if(h3_ele.length)for(var i=0;i<h3_ele.length;i++)"teal"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"turquoise"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"pink"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"nikeri"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"orange"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container callout"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container callout"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container instructions"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container instructions"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container colourbox"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container colourbox"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container references"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container references"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner big"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner medium"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner small"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"fullwidth"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"floatright"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"floatleft"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"flipcard"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"tabs"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"grid"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"accordion"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Accordion"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"popup"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"fluidvideo"==h3_ele[i].textContent&&(h3_ele[i].style.display="none");var h4_ele=document.querySelectorAll("h4");if(h4_ele.length)for(i=0;i<h4_ele.length;i++)"front"==h4_ele[i].textContent&&(h4_ele[i].style.display="none"),"back"==h4_ele[i].textContent&&(h4_ele[i].style.display="none"),"column"==h4_ele[i].textContent&&(h4_ele[i].style.display="none");var instr_ele=document.getElementsByClassName("oneDeakin_instructions");for(i=0;i<instr_ele.length;++i)(item=instr_ele[i]).style.display="none";var hr_ele=document.getElementsByTagName("hr");for(i=0;i<hr_ele.length;++i)(item=hr_ele[i]).style.display="none"}
</script></div>
<div style="position: static !important;"></div>
<div style="position: static !important;"></div>
<div style="position: static !important;"></div></body></html>