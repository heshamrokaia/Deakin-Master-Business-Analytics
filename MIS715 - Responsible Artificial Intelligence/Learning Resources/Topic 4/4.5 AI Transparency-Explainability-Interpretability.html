<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OneDeakin CloudDeakin Template</title>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css?version=202001061835" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <!-- prod -->
    <link rel="stylesheet" type="text/css" href="/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.css?v=20220329">
    <link rel="stylesheet" type="text/css" href="/content/deakin-embedded-comments/embeddedComments.css?v=20210208">
</head><body><div class="oneDeakin_instructions" style="font-size: 1rem; background: #e9ecef; padding: .4rem 1rem; border-radius: .3rem; margin-bottom: 1rem;">
<p><strong>OneDeakin template features</strong></p>
<blockquote>
<p>The OneDeakin template is full of features that help you advance the narrative and make learning and teaching happen.</p>
</blockquote>
<p>The CloudDeakin DLF Apps site contains information on all the template features, and how and when to use them. Accessing this site requires a simple two step process.</p>
<p><strong>Step 1:</strong> Use this form to be <a title="enrol in the CloudDeakin DLF Apps site" href="https://forms.office.com/r/0p7xpyMThG" target="blank">enrolled in the CloudDeakin DLF Apps site</a>.</p>
<p><strong>Step 2: </strong><span style="text-decoration: underline;">Only after you have enrolled in Step 1 above</span>, you can then access the <a title="access the CloudDeakin DLF Apps site" href="/d2l/home/1308183" target="blank">DLF Apps site</a> or search for 'DLF Apps' in the Sites Grid Menu.</p>
</div>
<div class="oneDeakin_instructions" style="font-size: 1rem; background: #e9ecef; padding: .4rem 1rem; border-radius: .3rem;">
<p><strong>OneDeakin Template Colours</strong></p>
<p>Define the OneDeakin Template colour by using the Heading3 'teal', 'turquoise', 'orange' or 'pink'.</p>
<p>When your page is published, this Heading3 will be removed from view. It it important that this first Heading3 remains in the OneDeakin template.</p>
</div>
<h3>teal</h3>
<h3>banner medium bus/inf/information-systems-12</h3>
<!-- CONTENT STARTS HERE -->
<h2>Transparency/Explainability/Interpretability</h2>
<p>The concept of AI transparency refers to The capability of people who use, regulate, and are impacted by AI systems to:&nbsp;</p>
<blockquote>
<p>describe, inspect, and reproduce the mechanisms by which AI systems make decisions and learns to adapt to their environments and to governance of the data used to created<br><em>(<a href="https://medium.com/@virginiadignum/the-art-of-ai-accountability-responsibility-transparency-48666ec92ea5#:~:text=Transparency%20refers%20to%20the%20need,of%20the%20data%20used%20created" target="_blank" rel="noopener">Dignum</a>, 2018, para. 6)</em></p>
</blockquote>
<p>One of the reasons why people might be afraid of AI, is that AI technologies and algorithmic decision-making can be hard to explain. When we can explain, justify, and interpret AI decision-making models, perhaps our fear of AI systems might reduce. While some AI technologies are straightforward to explain, for instance semantic reasoning, planning algorithms and some optimisation methods, some other AI technologies especially data-driven models like Machine Learning (ML), the relation between input and output of the models is much harder to explain.&nbsp;</p>
<p>The point of transparent AI is that the outcome of an AI model can be properly explained, interpreted, justified, and communicated. Transparent AI can also be called as explainable, justifiable, and interpretable AI. It is equally important to be explicit and open about the data sources, development processes, and stakeholders when it comes to transparency.</p>
<p>AI transparency or algorithmic "transparency" has many facets, but when it comes to institutional actors, it requires clarity in the selection, implementation, and technical aspects of automated decision-making systems. In a nutshell, AI transparency is to understand how an AI has made a given decision.&nbsp;</p>
<p>According to <a href="https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.html" target="_blank" rel="noopener">AWS</a>, while AI explainability refers to how to take a machine learning (ML) model and explain the behaviour in human term, whereas interpretability refers to a high model of AI transparency when a business needs to understand exactly why and how AI model is generating predictions and they need to observe the inner mechanics of AI or Machine Learning method. It is also worth to note there is a trade-off between interpretability and performance given that AI model explainability can be employed in any AI/ML use case, but when detailed transparency is required, then AI/ML method selection will become limited as explained by AWS below.</p>
<p><img src="MIS715%204.5%20interpretabililty%20vs%20performance.png" alt="graph showing interpretability, from low to high on the Y axis and performance, from poor to high on the X axis. The graph shows a sloped dotted line beginning at high interpretability and poor performance, top left, down to poor interpretability and high performance, bottom right, and where the AI/ML model sits. From top left of the line to bottom right: Linear regression, decision trees, logistic regression, nalve bayes, K-nearest neighbours, support vector machine, ensemble methods and neural networks." title="raph showing interpretability, from low to high on the Y axis and performance, from poor to high on the X axis." width="545" height="418" style="display: block; margin-left: auto; margin-right: auto;"></p>
<p>Source: <a href="https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.html">AWS White paper</a></p>
<p></p>
<h3><i class="fa fa-book" style="font-size: 24px;"></i><strong style="font-size: 1em;"> Read</strong><span style="font-size: 1em;">&nbsp;</span></h3>
<p>Read the <a href="https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.html" target="_blank" rel="noopener">ASW White paper</a> and reflect on why organisations should provide interpretable and explainable AI-derive decision for those who operate them and those affected by them. &nbsp;We’ll discuss this further in class.&nbsp;</p>
<h3>Transparency and explainability in Australia’s Artificial Intelligence Ethics Framework&nbsp;</h3>
<p>The Australia’s AI Ethics Framework highlighted that achieving transparency in AI systems through responsible disclosure is important to each stakeholder group for the following reasons:</p>
<ul>
<li>for users, what the system is doing and why</li>
<li>for creators, including those undertaking the validation and certification of AI, the systems’ processes and input data</li>
<li>for those deploying and operating the system, to understand processes and input data</li>
<li>for an accident investigator, if accidents occur</li>
<li>for regulators in the context of investigations</li>
<li>for those in the legal process, to inform evidence and decision‐making</li>
<li>for the public, to build confidence in the technology</li>
</ul>
<p style="text-align: right;">Source: <a href="https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles" target="_blank" rel="noopener">Australia’s AI Ethics Principles</a> (Department of Industry, Science and Resources)</p>
<p>Responsible disclosures should be provided in a timely manner and provide reasonable justifications for AI systems outcomes. This includes information that helps people understand outcomes, like key factors used in decision making. This principle also aims to ensure people have the ability to find out when an AI system is engaging with them (regardless of the level of impact) and are able to obtain a reasonable disclosure regarding the AI system.&nbsp;</p>
<p>Stakeholder involvement should be considered in the development of models that utilize human data, affect human beings, or may have other morally significant effects. When these systems are utilised in ways that have an impact on people's lives, there should be sufficient consultation and review, such that accountability and transparency are built into the implementation process (Goldenfein, 2019). Openness and control over the entire learning and training process may benefit transparency. Additionally, if we can maintain openness in all aspects of the system, trust in the system will increase.</p>
<h3><em class="fa fa-eye" style="font-size: 24px;"></em><strong style="font-size: 1em;">&nbsp;Watch</strong></h3>
<p>In the following video Microsoft describe what transparency looks like regarding responsible AI.</p>
<p><a href="https://www.youtube.com/watch?v=is4YFh8gVeg&amp;feature=youtube_gdata_player" target="_blank" rel="noopener">Microsoft Responsible AI Transparency - please view directly in YouTube</a></p>
<p>In the AI development process, the following approaches are suggested by Ronan et al (2020) to increase the transparency of AI models:</p>
<ul>
<li>Organisations should provide a consistent documentation alongside code implementation to identify use cases and follow a traceability process essential for industry applications, particularly in sensitive areas. Documentation (such as Datasheets for Datasets template by Gabru et al (2021)) to facilitate communication between dataset creators and consumers could be used to enhance the transparency of data used in AI and machine learning model</li>
<li>Explanatory approaches in AI should not only focus on the aspect of how well a human could understand the decisions in the given context but also how the decisions can be explicitly explained to people.&nbsp;</li>
</ul>
<p></p>
<h3>Activity</h3>
<h3></h3>
<h3><em class="fa fa-eye" style="font-size: 24px;"></em><strong style="font-size: 1em;">&nbsp;Watch</strong></h3>
<p>In the following video Timnit Gebru discusses the motivation and thinking behind their review article "Datasheets for Datasets". She also details the many challenges that this framework still has to face.</p>
<p>As you watch the video consider how the proposed mechanisms could help enhance AI transparency. Do you think its practically implementable? What are some of the challenges to its adoption?&nbsp;&nbsp;</p>
<p style="text-align: center;"><iframe width="500" height="281" src="https://www.youtube.com/embed/R7s7_T4yXak?feature=oembed&amp;wmode=opaque&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" title="December 2021 CACM: Datasheets for Datasets"></iframe></p>
<p></p>
<p><!-- CONTENT ENDS HERE --></p>
<div><iframe src="/content/deakin-embedded-comments/embedded-comments-loader.html?v=20201006" style="position: absolute; left: -9999px; top: -9999px; width: 0px; height: 0px;"></iframe> <!--FORUMVARIABLESTART-->
<div style="display: none;" data-forumname="null"></div>
<!--FORUMVARIABLEEND--></div>
<div>
<script src="https://s.brightspace.com/lib/jquery/2.2.4/jquery.min.js?version=202001061835" integrity="sha384-rY/jv8mMhqDabXSo+UCggqKtdmBfd3qC2/KvyTDNQ6PcUJXaxK1tMepoQda4g5vB" crossorigin="anonymous"></script>
<!-- prod -->
<script src="/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.js?v=20220329"></script>
<script src="/content/deakinscripts/moment/moment.2.21.js"></script>
<script src="/content/deakin-embedded-comments/embeddedComments.js?v=20210208"></script>
<script>
if(navigator.onLine)console.log("online"),$(document).ready((function(){var e,t,n;-1<window.location.href.indexOf("https://d2l")?console.log("in CloudDeakin"):(console.log("not in CloudDeakin"),$("body").prepend('<div style="background:#990050;color:#FFFFFF;padding:1rem;text-align:center;"><p>You are viewing downloaded HTML content outside of CloudDeakin.<br>Some content, images, links, interactives etc. may not render or function as they do when they are viewed in CloudDeakin.</p></div>'),$.expr[":"].textEquals=$.expr[":"].textEquals||$.expr.createPseudo((function(e){return function(t){return $(t).text().match("^"+e+"$")}})),$("h3:textEquals('container'), h3:textEquals('Container'),  h3:textEquals('container callout'), h3:textEquals('Container callout'), h3:textEquals('container instructions'), h3:textEquals('Container instructions'), h3:textEquals('container colourbox'), h3:textEquals('Container colourbox'), h3:textEquals('container references'), h3:textEquals('Container references'), h3:textEquals('banner'), h3:textEquals('banner big'), h3:textEquals('banner medium'), h3:textEquals('banner small'), h3:textEquals('fullwidth'), h3:textEquals('floatright'), h3:textEquals('floatleft'), h3:textEquals('flipcard'), h3:textEquals('tabs'), h3:textEquals('grid'), h3:textEquals('accordion'), h3:textEquals('Accordion'), h3:textEquals('popup'), h3:textEquals('fluidvideo'), h3:textEquals('teal'), h3:textEquals('turquoise'), h3:textEquals('pink'), h3:textEquals('orange'), h3:textEquals('nikeri'), h4:textEquals('front'), h4:textEquals('back'), h4:textEquals('column'), h3:contains('banner'), hr, .oneDeakin_instructions").remove(),$("body").addClass("oneDeakin"),$("body").removeAttr("style"),$("body").css({'font-family':'"HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif','font-size':'16px','margin':'10px auto','max-width':'90%'}),n="<link rel='stylesheet' href='https://d2l.deakin.edu.au/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.css' type='text/css' media='screen'>",(t=(e=$("head")).find("link[rel='stylesheet']:last")).length?t.after(n):e.append(n))}));else{console.log("offline");var body=document.getElementsByTagName("body")[0],newDiv=document.createElement("div");newDiv.innerHTML='<p style="background:#990050;color:#FFFFFF;padding:1rem;text-align:center;width:100%;font-size:14px;">You are viewing downloaded HTML content outside of CloudDeakin without any internet connection.<br>Some content, images, links, interactives etc. may not render or function as they do when they are viewed in CloudDeakin.</p>',body.insertBefore(newDiv,body.firstChild);var h3_ele=document.querySelectorAll("h3");if(h3_ele.length)for(var i=0;i<h3_ele.length;i++)"teal"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"turquoise"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"pink"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"nikeri"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"orange"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container callout"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container callout"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container instructions"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container instructions"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container colourbox"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container colourbox"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container references"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container references"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner big"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner medium"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner small"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"fullwidth"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"floatright"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"floatleft"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"flipcard"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"tabs"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"grid"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"accordion"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Accordion"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"popup"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"fluidvideo"==h3_ele[i].textContent&&(h3_ele[i].style.display="none");var h4_ele=document.querySelectorAll("h4");if(h4_ele.length)for(i=0;i<h4_ele.length;i++)"front"==h4_ele[i].textContent&&(h4_ele[i].style.display="none"),"back"==h4_ele[i].textContent&&(h4_ele[i].style.display="none"),"column"==h4_ele[i].textContent&&(h4_ele[i].style.display="none");var instr_ele=document.getElementsByClassName("oneDeakin_instructions");for(i=0;i<instr_ele.length;++i)(item=instr_ele[i]).style.display="none";var hr_ele=document.getElementsByTagName("hr");for(i=0;i<hr_ele.length;++i)(item=hr_ele[i]).style.display="none"}
</script>
</div>
<div style="position: static !important;"></div>
<div style="position: static !important;"></div>
<div style="position: static !important;"></div>
<p></p></body></html>