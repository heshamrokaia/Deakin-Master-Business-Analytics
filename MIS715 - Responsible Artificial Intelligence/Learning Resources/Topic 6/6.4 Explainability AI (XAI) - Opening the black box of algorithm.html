<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OneDeakin CloudDeakin Template</title>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css?version=202001061835" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <!-- prod -->
    <link rel="stylesheet" type="text/css" href="/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.css?v=20220329">
    <link rel="stylesheet" type="text/css" href="/content/deakin-embedded-comments/embeddedComments.css?v=20210208">
</head><body><div class="oneDeakin_instructions" style="font-size: 1rem; background: #e9ecef; padding: .4rem 1rem; border-radius: .3rem; margin-bottom: 1rem;">
<p><strong>OneDeakin template features</strong></p>
<blockquote>
<p>The OneDeakin template is full of features that help you advance the narrative and make learning and teaching happen.</p>
</blockquote>
<p>The CloudDeakin DLF Apps site contains information on all the template features, and how and when to use them. Accessing this site requires a simple two step process.</p>
<p><strong>Step 1:</strong> Use this form to be <a title="enrol in the CloudDeakin DLF Apps site" href="https://forms.office.com/r/0p7xpyMThG" target="blank">enrolled in the CloudDeakin DLF Apps site</a>.</p>
<p><strong>Step 2: </strong><span style="text-decoration: underline;">Only after you have enrolled in Step 1 above</span>, you can then access the <a title="access the CloudDeakin DLF Apps site" href="/d2l/home/1308183" target="blank">DLF Apps site</a> or search for 'DLF Apps' in the Sites Grid Menu.</p>
</div>
<div class="oneDeakin_instructions" style="font-size: 1rem; background: #e9ecef; padding: .4rem 1rem; border-radius: .3rem;">
<p><strong>OneDeakin Template Colours</strong></p>
<p>Define the OneDeakin Template colour by using the Heading3 'teal', 'turquoise', 'orange' or 'pink'.</p>
<p>When your page is published, this Heading3 will be removed from view. It it important that this first Heading3 remains in the OneDeakin template.</p>
</div>
<h3>teal</h3>
<h3>banner medium bus/inf/information-systems-21</h3>
<!-- CONTENT STARTS HERE -->
<h2>Explainable AI (XAI) - Opening the black box algorithm</h2>
<p>AI systems are evolving rapidly and have advanced to a point where they are now involved in making critical decisions or predictions for a person’s wellbeing. In order to have confidence in these decisions, it is essential to know how the AI system arrives at a particular output and what algorithms are used. &nbsp;Without having this understanding, the results may be undesirable or questionable. In some instances the algorithm's calculations or how a particular output was reached cannot be examined or interpreted &nbsp;– which is why it is referred to as a black box algorithm. This lack of understanding creates a significant distrust in the system.</p>
<p>This has led to the birth of the field of Explainable AI (XAI) which uses process and methods to allow humans to understand and put their trust in the outputs generated from AI algorithms. The goal of XAI is to make the mechanisms of AI algorithms transparent and the outputs understandable to humans. Understanding is the foundation upon which trust in someone or something is built. If an AI system’s output does not match a user’s expectations and the mechanisms are not understandable, it can lead to a loss of trust. Explainability helps to confirm predictions, improve and advance models and to gain new insights into the initial concerns.</p>
<p>Explanations in general are ethically important for the following reasons:</p>
<ul>
<li><span style="color: var(--clr-font-base); font-family: var(--font-opensans);">They demonstrate respect for the person being explained to.&nbsp; </span></li>
<li>They enable the person being explained to, to make informed decisions and change their behaviour, giving them control over future decisions.</li>
<li>They allow for assessment of the model’s rules that govern how inputs are turned into outputs against ethical, reputational, regulatory, and legal standards.&nbsp;&nbsp;</li>
</ul>
<p>Fundamentally, there are two types of algorithms that can be distinguished: 1) transparent models and 2) black-box models. Transparent models benefit from their fundamental design which allows the model to provide explanations based on it whereas black-box models do not provide such insights.</p>
<p>The following table (Hamm et al 2021 p. 3) compares the two models:&nbsp;</p>
<table style="border-collapse: collapse; width: 99.977%; height: 64px;" border="1"><colgroup><col style="width: 33.2721%;"><col style="width: 33.2721%;"><col style="width: 33.2721%;"></colgroup>
<tbody>
<tr style="height: 32px;">
<td style="height: 32px;"></td>
<td style="height: 32px; background-color: #a2c4c9;"><strong>Transparent models</strong></td>
<td style="height: 32px; background-color: #a2c4c9;"><strong>Black-box models</strong></td>
</tr>
<tr style="height: 32px;">
<td style="height: 32px;"><strong>Definition</strong></td>
<td style="height: 32px;">Models that can fully and understandably explain how an algorithm operates and given an input, can tell what the output will be and why&nbsp;</td>
<td style="height: 32px;">Models that create internal structures that determine outputs but are opaque to external parties. Even the programmers cannot tell why a particular output was produced&nbsp;</td>
</tr>
<tr style="height: 0px;">
<td style="height: 0px;"><strong>Agnostic</strong></td>
<td style="height: 0px;">Possible</td>
<td style="height: 0px;">Possible&nbsp;<span style="font-size: 12.0pt; font-family: 'Times New Roman', serif; color: black;"> </span></td>
</tr>
<tr style="height: 0px;">
<td style="height: 0px;"><strong>Model specific</strong></td>
<td style="height: 0px;">Not required</td>
<td style="height: 0px;">Possible</td>
</tr>
</tbody>
</table>
<p style="text-align: center;"><strong>Table 1. Classification of Explainable AI techniques (Source: Hamm et al 2021 p. 3)&nbsp;</strong></p>
<p></p>
<h3>Activity</h3>
<h3>Container colourbox</h3>
<h3>Test your knowledge</h3>
<p>After reading the table above comparing Transparent and Black-box models can you match the following example Algorithms.</p>
<p><em class="fa fa-info-circle" style="font-size: 24px;"></em><span style="font-size: 1em;">&nbsp;Click on the words and drag them into the correct columns. Click the submit button to check your answers.</span></p>
<hr>
<p><iframe src="/d2l/common/dialogs/quickLink/quickLink.d2l?ou=1527351&amp;type=lti&amp;rCode=DeakinUniversity-3823886" title="MIS715 6.4 Explainability - models" allowfullscreen="allowfullscreen" allow="microphone *; camera *; autoplay *" height="600" width="779"></iframe></p>
<p></p>
<h3>How to reduce the issues associated with black box algorithms&nbsp;</h3>
<p>Due to the importance and demand on making the black box algorithm process transparent, regulations are now being established to make AI systems accountable. &nbsp;The European General Data Protection Regulation (GDPR) requires that AI systems be able to explain their underlying mechanism (European Union 2016). These regulations not only strengthen accountability, but also benefits fields such as machine learning systems in deep learning and neural networks designed to teach humans that would require a sound level of explanation.</p>
<p>Organisations must consider the importance of explainability for each specific use case and determine the balance against other goals, such as accuracy.</p>
<p>Some guidelines include: &nbsp;</p>
<ul>
<li>Machine explainability is necessary when: &nbsp;
<ul>
<li>showing respect is ethically required&nbsp;</li>
<li>people need to understand how to improve results&nbsp;</li>
<li>people need to know how to approach and make a decision&nbsp;</li>
<li>the outputs are unexpected&nbsp;</li>
<li>justification of action is needed from an ethical, regulatory, or legal perspective).</li>
</ul>
</li>
<li>Appropriate explanations should be: &nbsp;
<ul>
<li>true (or true enough for the case at hand)&nbsp;</li>
<li>easy, efficient, and effective for its intended use&nbsp;</li>
<li>understandable for the intended audience&nbsp;</li>
<li>explanation should also include justification of decisions, actions, processes, etc. Organisations should also determine who is best suited to make those assessment, recognising that AI developers and data scientists are not the experts in these areas.</li>
</ul>
</li>
</ul>
<p></p>
<hr>
<p><!-- CONTENT ENDS HERE --></p>
<div><iframe src="/content/deakin-embedded-comments/embedded-comments-loader.html?v=20201006" style="position: absolute; left: -9999px; top: -9999px; width: 0px; height: 0px;"></iframe> <!--FORUMVARIABLESTART-->
<div style="display: none;" data-forumname="null"></div>
<!--FORUMVARIABLEEND--></div>
<div>
<script src="https://s.brightspace.com/lib/jquery/2.2.4/jquery.min.js?version=202001061835" integrity="sha384-rY/jv8mMhqDabXSo+UCggqKtdmBfd3qC2/KvyTDNQ6PcUJXaxK1tMepoQda4g5vB" crossorigin="anonymous"></script>
<!-- prod -->
<script src="/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.js?v=20220329"></script>
<script src="/content/deakinscripts/moment/moment.2.21.js"></script>
<script src="/content/deakin-embedded-comments/embeddedComments.js?v=20210208"></script>
<script>
if(navigator.onLine)console.log("online"),$(document).ready((function(){var e,t,n;-1<window.location.href.indexOf("https://d2l")?console.log("in CloudDeakin"):(console.log("not in CloudDeakin"),$("body").prepend('<div style="background:#990050;color:#FFFFFF;padding:1rem;text-align:center;"><p>You are viewing downloaded HTML content outside of CloudDeakin.<br>Some content, images, links, interactives etc. may not render or function as they do when they are viewed in CloudDeakin.</p></div>'),$.expr[":"].textEquals=$.expr[":"].textEquals||$.expr.createPseudo((function(e){return function(t){return $(t).text().match("^"+e+"$")}})),$("h3:textEquals('container'), h3:textEquals('Container'),  h3:textEquals('container callout'), h3:textEquals('Container callout'), h3:textEquals('container instructions'), h3:textEquals('Container instructions'), h3:textEquals('container colourbox'), h3:textEquals('Container colourbox'), h3:textEquals('container references'), h3:textEquals('Container references'), h3:textEquals('banner'), h3:textEquals('banner big'), h3:textEquals('banner medium'), h3:textEquals('banner small'), h3:textEquals('fullwidth'), h3:textEquals('floatright'), h3:textEquals('floatleft'), h3:textEquals('flipcard'), h3:textEquals('tabs'), h3:textEquals('grid'), h3:textEquals('accordion'), h3:textEquals('Accordion'), h3:textEquals('popup'), h3:textEquals('fluidvideo'), h3:textEquals('teal'), h3:textEquals('turquoise'), h3:textEquals('pink'), h3:textEquals('orange'), h3:textEquals('nikeri'), h4:textEquals('front'), h4:textEquals('back'), h4:textEquals('column'), h3:contains('banner'), hr, .oneDeakin_instructions").remove(),$("body").addClass("oneDeakin"),$("body").removeAttr("style"),$("body").css({'font-family':'"HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif','font-size':'16px','margin':'10px auto','max-width':'90%'}),n="<link rel='stylesheet' href='https://d2l.deakin.edu.au/content/enforced/1308183-cd_dlf_apps/onedeakin/onedeakin.css' type='text/css' media='screen'>",(t=(e=$("head")).find("link[rel='stylesheet']:last")).length?t.after(n):e.append(n))}));else{console.log("offline");var body=document.getElementsByTagName("body")[0],newDiv=document.createElement("div");newDiv.innerHTML='<p style="background:#990050;color:#FFFFFF;padding:1rem;text-align:center;width:100%;font-size:14px;">You are viewing downloaded HTML content outside of CloudDeakin without any internet connection.<br>Some content, images, links, interactives etc. may not render or function as they do when they are viewed in CloudDeakin.</p>',body.insertBefore(newDiv,body.firstChild);var h3_ele=document.querySelectorAll("h3");if(h3_ele.length)for(var i=0;i<h3_ele.length;i++)"teal"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"turquoise"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"pink"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"nikeri"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"orange"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container callout"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container callout"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container instructions"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container instructions"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container colourbox"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container colourbox"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"container references"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Container references"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner big"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner medium"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"banner small"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"fullwidth"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"floatright"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"floatleft"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"flipcard"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"tabs"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"grid"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"accordion"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"Accordion"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"popup"==h3_ele[i].textContent&&(h3_ele[i].style.display="none"),"fluidvideo"==h3_ele[i].textContent&&(h3_ele[i].style.display="none");var h4_ele=document.querySelectorAll("h4");if(h4_ele.length)for(i=0;i<h4_ele.length;i++)"front"==h4_ele[i].textContent&&(h4_ele[i].style.display="none"),"back"==h4_ele[i].textContent&&(h4_ele[i].style.display="none"),"column"==h4_ele[i].textContent&&(h4_ele[i].style.display="none");var instr_ele=document.getElementsByClassName("oneDeakin_instructions");for(i=0;i<instr_ele.length;++i)(item=instr_ele[i]).style.display="none";var hr_ele=document.getElementsByTagName("hr");for(i=0;i<hr_ele.length;++i)(item=hr_ele[i]).style.display="none"}
</script></div>
<div style="position: static !important;"></div>
<div style="position: static !important;"></div>
<div style="position: static !important;"></div>
<p></p></body></html>