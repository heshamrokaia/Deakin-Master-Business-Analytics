{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP2Th8B0LLey"
      },
      "source": [
        "## MIS780 - Advanced Artificial Intelligence for Business\n",
        "\n",
        "## Week 1 - Part 2: Getting Started with Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0vSWcazLLe3"
      },
      "source": [
        "In this session, you will get familar with essential libraries and procedure for developing machine learning solutions.\n",
        "\n",
        "Make sure that the following packages are installed in your Anaconda environment: `numpy`, `scipy`, `matplotlib`, `ipython`, `scikit-learn` and `pandas`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwvMoA7Q-nih"
      },
      "source": [
        "\n",
        "## Table of Content\n",
        "\n",
        "\n",
        "1. [Essential Libraries](#cell_Essential)\n",
        "    - [NumPy](#cell_NumPy)\n",
        "    - [SciPy](#cell_SciPy)\n",
        "    - [matplotlib](#cell_matplotlib)\n",
        "    - [pandas](#cell_pandas)\n",
        "    \n",
        "\n",
        "2. [An Application: Classifying Iris Species](#cell_Iris)\n",
        "    - [Iris dataset](#cell_dataset)\n",
        "    - [Training and Testing Data](#cell_TrainingTesting)\n",
        "    - [Data Splitting Exercise](#cell_cell_DataSplitingExercise)\n",
        "    - [Examine the Data](#cell_Examine)\n",
        "    - [Making Predictions](#cell_Predictions)\n",
        "    - [Evaluating the Mode](#cell_Evaluating)\n",
        "    \n",
        "    \n",
        "3. [Exercise: k-folds cross-validation](#cell_Exercise1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THnW6RPgLLf6"
      },
      "source": [
        "<a id = \"cell_Essential\"></a>\n",
        "### <font color=\"blue\">1. Essential Libraries\n",
        "\n",
        "<a id = \"cell_NumPy\"></a>\n",
        "### NumPy\n",
        "\n",
        "`numpy` is one of the fundamental packages for scientific computing in Python. It contains functionality for multidimensional arrays, high-level mathematical func‐tions such as linear algebra operations and random number generators.\n",
        "\n",
        "https://numpy.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG-9AQrmLLf7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"x:\\n{}\".format(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#index the first row of x\n",
        "print(\"x[0]: {}\".format(x[0]))\n"
      ],
      "metadata": {
        "id": "9mVyMQqOtqsU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "# index the second row of x\n",
        "\n",
        "# index the first column of x\n",
        "\n",
        "# append a new row\n",
        "\n",
        "# append a new column\n"
      ],
      "metadata": {
        "id": "-JM6DKfLngm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm9IgbLyLLgU"
      },
      "source": [
        "<a id = \"cell_SciPy\"></a>\n",
        "### SciPy\n",
        "\n",
        "`scipy` is a collection of functions for scientific computing in Python. It provides, among other functionality, advanced linear algebra routines, mathematical function optimization, signal processing, special mathematical functions, and statistical distributions.\n",
        "\n",
        "https://scipy.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually it is not possible to create dense representations of sparse data (as they would not  fit  into  memory),  so  we  need  to  create  sparse  representations  directly."
      ],
      "metadata": {
        "id": "cHelVR_8LLgg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zilCIz-GLLga"
      },
      "outputs": [],
      "source": [
        "# Create a 2D NumPy array with a diagonal of ones, and zeros everywhere else\n",
        "eye = np.eye(4) # Return a 2-D array with ones on the diagonal and zeros elsewhere, N (=4) here returns the number of rows in the array\n",
        "print(\"NumPy array:\\n{}\".format(eye))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "\n",
        "data = np.ones(4)\n",
        "print(\"data :\\n{}\".format(data))\n",
        "row_indices = np.arange(4)\n",
        "print(\"row_indices :\\n{}\".format(row_indices))\n",
        "col_indices = np.arange(4)\n",
        "\n",
        "eye_coo = sparse.coo_matrix((data, (row_indices, col_indices)))   #creates a sparse matrix in the COO (Coordinate) format.\n",
        "print(\"\\nCOO representation:\\n{}\".format(eye_coo))"
      ],
      "metadata": {
        "id": "zshg7IvZLLgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "# Generate a 4x4 array with random integers\n",
        "\n",
        "# make 2 elements zero in each row\n",
        "\n",
        "# get the non zero indices of the array as row, col\n",
        "row, col = np.nonzero(data)\n",
        "\n",
        "#convert the sparse array into COO\n",
        "\n",
        "# Print the Sparse Array\n",
        "\n",
        "# Print the COO Matrix\n"
      ],
      "metadata": {
        "id": "NlOGdtUiqslQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3vLIE_bLLhC"
      },
      "source": [
        "<a id = \"cell_matplotlib\"></a>\n",
        "### matplotlib\n",
        "\n",
        "`matplotlib` is the primary scientific plotting library in Python. It provides functionsfor making publication-quality visualizations such as line charts, histograms, scatterplots, and so on. Visualizing your data and different aspects of your analysis can give you important insights.  \n",
        "\n",
        "https://matplotlib.org/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcq185ULLLhD",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt #imports pyplot module from matplotlib\n",
        "\n",
        "# Generate a sequence of 100 numbers from -10 to 10 (inclusive)\n",
        "x = np.linspace(-10, 10, 100)\n",
        "\n",
        "# Create a second array using sine function for each element in the (x) array\n",
        "y = np.sin(x)\n",
        "\n",
        "# The plot function makes a line chart of one array against another\n",
        "plt.plot(x, y, marker=\"x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5Kx0MKLLLhZ"
      },
      "source": [
        "<a id = \"cell_pandas\"></a>\n",
        "### pandas\n",
        "\n",
        "`pandas` is a Python library for data wrangling and analysis. It is built around a data structure called the **DataFrame**. A pandas **DataFrame** is a table, similar to an **Excel** spreadsheet. pandas provides a great range of methods to modify and operate on this table; in particular, it allows **SQL**-like queries and joins of tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j7kVvnnLLhd",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create a simple dataset of people\n",
        "data = {'Name': [\"John\", \"Anna\", \"Peter\", \"Linda\"],\n",
        "        'Location' : [\"New York\", \"Paris\", \"Berlin\", \"London\"],\n",
        "        'Age' : [24, 13, 53, 33]}\n",
        "\n",
        "data_pandas = pd.DataFrame(data)\n",
        "# IPython.display allows \"pretty printing\" of dataframes\n",
        "# in the Jupyter notebook\n",
        "display(data_pandas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glnQnKz6LLhi"
      },
      "source": [
        "There are several possible ways to query this table. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DC97cQs2LLhj",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Select all rows that have an age column greater than 30\n",
        "display(data_pandas[data_pandas.Age > 30])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - display names starting with P\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dYxRbj5NSHAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise - Select all records with a Location paris\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s-m52SsCRi49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise -adding another data row to data_pandas\n",
        "\n",
        "# Creating a new row as a DataFrame named new_row\n",
        "#new_row =\n",
        "\n",
        "# add the new row ro the data_pandat\n",
        "data_pandas = pd.concat([data_pandas, new_row], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "_wA2JX77Snfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUcMPHTMLLiS"
      },
      "source": [
        "<a id = \"cell_Iris\"></a>\n",
        "### <font color=\"blue\">2. An Application: Classifying Iris Species\n",
        "\n",
        "In this section, we  will go through a simple machine learning application  and create our first model.  Our goal is to build a machine learning model that can learn from the measurements of  the iris flowers whose species is known, so that we can predict the species for a new iris.\n",
        "\n",
        "<a id = \"cell_dataset\"></a>\n",
        "### Iris dataset\n",
        "The data we will use for this example is the Iris dataset, a classical dataset in machine learning and statistics. We can load it by calling the `load_iris` function.\n",
        "\n",
        "The iris object that is returned by load_iris is a Bunch object, which is very similar to a dictionary. It contains keys and values:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_dataset = load_iris()\n",
        "print(\"Keys of iris_dataset: \\n{}\".format(iris_dataset.keys()))"
      ],
      "metadata": {
        "id": "NTaPssJ_LLiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The  value  of  the  key  `DESCR`  is  a  short  description  of  the  dataset."
      ],
      "metadata": {
        "id": "4bJEQg_MLLiU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6bV4vC9LLiX"
      },
      "outputs": [],
      "source": [
        "print(iris_dataset['DESCR'][:193] + \"\\n...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTDUWNsPLLie"
      },
      "source": [
        "The  value  of  the  key  `target_names`  is  an  array  of  strings,  containing  the  species  offlower that we want to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5ee7L9mLLif"
      },
      "outputs": [],
      "source": [
        "print(\"Target names: {}\".format(iris_dataset['target_names']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ID6qNctLLil"
      },
      "source": [
        "The value of `feature_names` is a list of strings, giving the description of each feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT18fhA8LLim"
      },
      "outputs": [],
      "source": [
        "print(\"Feature names: \\n{}\".format(iris_dataset['feature_names']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-YaXqCSLLir"
      },
      "source": [
        "The data itself is contained in the target and data fields. data contains the numeric measurements of sepal length, sepal width, petal length, and petal width in a`numpy` array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIZ3IGCILLis"
      },
      "outputs": [],
      "source": [
        "print(\"Type of data: {}\".format(type(iris_dataset['data'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0sASGehLLiz"
      },
      "source": [
        "The rows in the data array correspond to flowers, while the columns represent  the four measurements that were taken for each flower.\n",
        "\n",
        "We  see  that  the  array  contains  measurements  for  150  different  flowers. Individual items are called **samples** in machine learning, and their propertiesare called **features**. The shape of the data array is the number of samples multiplied by the  number  of  features.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8-htgKSLLi0"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of data: {}\".format(iris_dataset['data'].shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Mk39mzf8LLjd"
      },
      "source": [
        "The  feature  values  for  the  first  five samples is shown below.\n",
        "\n",
        "From this data, we can see that all of the first five flowers have a petal width of 0.2 cm and that the first flower has the longest sepal, at 5.1 cm."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First five rows of data:\\n{}\".format(iris_dataset['data'][:5]))\n",
        "\n",
        "# Exercises\n",
        "# Select first two columns of first five rows\n",
        "\n",
        "# Select every other row\n",
        "\n",
        "#Select 1st and 3rd column of first 5 rows\n"
      ],
      "metadata": {
        "id": "DI609niBLLje",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The target array contains the species of each of the flowers that were measured"
      ],
      "metadata": {
        "id": "V62kYzxKLLjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wGHArWZLLji"
      },
      "outputs": [],
      "source": [
        "print(\"Type of target: {}\".format(type(iris_dataset['target'])))\n",
        "\n",
        "print(\"Shape of target: {}\".format(iris_dataset['target'].shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7mJiYNiLLjk"
      },
      "source": [
        "The species are encoded as integers from 0 to 2. The   meanings   of   the   numbers   are   given   by   the   `iris['target_names']`   array: **0** means **setosa**, **1** means **versicolor**, and **2** means **virginica**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9bnxwLRLLjk"
      },
      "outputs": [],
      "source": [
        "print(\"Target:\\n{}\".format(iris_dataset['target']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_NS6zzbLLjl"
      },
      "source": [
        "<a id = \"cell_TrainingTesting\"></a>\n",
        "### Training and Testing Data\n",
        "\n",
        "We  want  to  build  a  machine  learning  model  from  this  data  that  can  predict  the  species of iris for a new set of measurements. But before we can apply our model to new measurements, we  need  to  know its performance.\n",
        "\n",
        "This is usually done by splitting the labeled data (here,  our  150  flower  measurements) into  two  parts.  One  part  of  the data  is  used  to  build  our  machine  learning  model,  and  is  called  the  **training  data**. The rest of the data will be used to assess how well the model works; this is called the **test data** or **hold-out set**.\n",
        "\n",
        "We use the `train_test_split` function  that  shuffles and splits the  dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpz8oajsLLjp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
        "\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))\n",
        "\n",
        "print(\"\\nTraining labels distribution with stratify:\\n\", np.bincount(y_train))\n",
        "print(\"\\nTest labels distribution with stratify:\\n\", np.bincount(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trz9FkG9kBks"
      },
      "source": [
        "<a id = \"cell_DataSplitingExercise\"></a>\n",
        "\n",
        "#### <font color=\"blue\">Data Splitting Exercise\n",
        "\n",
        "Work in pairs and discuss answers to the following questions\n",
        "\n",
        "a. When you do not explicitly specify **`test_size`** in **`train_test_split()`**, Python uses the default value of `0.25`, which may work in many cases. However, what is the disadvantage of this approach?\n",
        "\n",
        "b. Read the documentation of the `train_test_split` function and examine the **`stratify`** parameter. What is its purpose? Based on your understanding of the `Iris` dataset, should we use `stratify` when splitting the data? Justify and implement your answer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Place your solution here"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ioPQpN7RmDOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = \"cell_Examine\"></a>\n",
        "### Examine the Data\n",
        "\n",
        "Before building a machine learning model it is often a good idea to inspect the data,to  see  if  the  task  is  easily  solvable  without  machine learning,  or  if  the  desired  infor‐mation might not be contained in the data.\n",
        "\n",
        "One of the best ways to inspect data is to visualize it using scatter plot. Unfortunately,  computer screens have only two dimensions, which allows us to plot only two (or maybe three) features at a time. One way around this problem is to do a pair plot, which looks at all possible pairs of features."
      ],
      "metadata": {
        "id": "vZnUQd69LLjx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zfw9EfrqLLj0",
        "scrolled": false,
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "# create dataframe from data in X_train\n",
        "# label the columns using the strings in iris_dataset.feature_names\n",
        "iris_dataframe = pd.DataFrame(\n",
        "    X_train, columns=iris_dataset.feature_names)\n",
        "print(iris_dataframe.head())\n",
        "#\n",
        "# create a scatter matrix from the dataframe, color by y_train\n",
        "grr = scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o',\n",
        "    hist_kwds={'bins': 20}, s=60, alpha=.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rZvY3UlLLj1"
      },
      "source": [
        "From  the  plots,  we  can  see  that  the  three  classes  seem  to  be  relatively  well  separatedusing  the  sepal  and  petal  measurements.  This  means  that  a  machine  learning  modelwill likely be able to learn to separate them.\n",
        "\n",
        "<a id = \"cell_k-Nearest\"></a>\n",
        "### Building k-Nearest Neighbors Model\n",
        "\n",
        "Now we can start building the actual machine learning model. There are many classification algorithms in `scikit-learn` that we could use. Here we will use a k-nearest neighbors classifier, which is easy to understand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4dFT7CYLLj1"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRn9iUKrLLj8"
      },
      "source": [
        "To build the model on the training set, we call the `fit` method of the `knn` object. The fit method returns the knn object itself (and modifies it in place), so we get a string representation of our classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJOHXNYOLLj8"
      },
      "outputs": [],
      "source": [
        "knn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = \"cell_Predictions\"></a>\n",
        "### Making Predictions\n",
        "\n",
        "We can now make predictions using this model on new data for which we might not know the correct labels.  Imagine we found an iris in the wild with a sepal length of **5 cm**, a sepal width of **2.9 cm**, a petal length of **1 cm**, and a petal width of **0.2 cm**. What species of iris would this be? We can put this data into a NumPy array."
      ],
      "metadata": {
        "id": "e3678xUuLLj9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgVnOhigLLj-"
      },
      "outputs": [],
      "source": [
        "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
        "#X_new = np.array([[5, 2.9, 1, 0.2],[5.1, 2.8, 1.1, 0.3]])\n",
        "\n",
        "print(\"X_new.shape: {}\".format(X_new.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqRZ2fA--niw"
      },
      "source": [
        "To make a prediction, we call the predict method of the `knn` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpQCy7_M-niw"
      },
      "outputs": [],
      "source": [
        "prediction = knn.predict(X_new)\n",
        "print(\"Prediction: {}\".format(prediction))\n",
        "print(\"Predicted target name: {}\".format(\n",
        "    iris_dataset['target_names'][prediction]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnDnNxZR-niw"
      },
      "source": [
        "Our model predicts that this new iris belongs to the class 0, meaning its species is **setosa**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3ClkWDGLLkG"
      },
      "source": [
        "<a id = \"cell_Evaluating\"></a>\n",
        "### Evaluating the Mode\n",
        "\n",
        "We can make a prediction for each iris in the test data and compare it against its label (the known species). We can measure how well the model works by\n",
        "computing the **accuracy**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "print(\"Test set predictions:\\n {}\".format(y_pred))"
      ],
      "metadata": {
        "id": "DWqLiEZ1LLkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLEykVxy-nix"
      },
      "outputs": [],
      "source": [
        "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dIwj0dO-nix"
      },
      "source": [
        "We can also use the `score` method of the `knn` object, which will compute the test set **accuracy** for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ6KSw5M-nix"
      },
      "outputs": [],
      "source": [
        "print(\"Test set score: {:.2f}\".format(knn.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5XvLWLO-nix"
      },
      "source": [
        "<a id = \"cell_Exercise1\"></a>\n",
        "### <font color=\"blue\">3. Exercise: k-folds cross-validation</font>\n",
        "\n",
        "Evaluate the performance of Support Vector Machine classifier on the iris data set using 10-folds cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd7kPIZx-nix"
      },
      "source": [
        "<details><summary><font color=\"blue\"><b>Click here for solution:</b></font></summary>\n",
        "import pandas\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "dataset = load_iris()\n",
        "X = dataset['data']\n",
        "y = dataset['target']\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=False)\n",
        "\n",
        "scores = []\n",
        "for train_index, test_index in cv.split(X):\n",
        "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
        "    svclassifier = SVC(kernel='linear')\n",
        "    svclassifier.fit(X_train, y_train)\n",
        "    scores.append(svclassifier.score(X_test, y_test))\n",
        "    \n",
        "print('Cross validation accuracy: \\n', scores)     \n",
        "print('Overall accuracy: ', np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXUC5FOe-nix"
      },
      "outputs": [],
      "source": [
        "#Place your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fNGLVcB-nix"
      },
      "source": [
        "### References:\n",
        "\n",
        "- Muller, A. C., & Guido, S. (2017). Introduction to machine learning with python: A guide for data scientists. O'Reilly Media, Sebastopol, CA 95472.  https://www.oreilly.com/library/view/introduction-to-machine/9781449369880/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}