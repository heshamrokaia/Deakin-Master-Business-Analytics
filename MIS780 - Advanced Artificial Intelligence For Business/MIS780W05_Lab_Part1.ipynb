{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrOi_QFRkVVa"
      },
      "source": [
        "## MIS780 - Advanced Artificial Intelligence for Business\n",
        "\n",
        "## Week 5 - Part 1: Classifying Images with CNN\n",
        "\n",
        "In this session, you will classify Images with deep learning packages (Tensorflow and Keras).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxnHUSM3kVVf"
      },
      "source": [
        "## Table of Content\n",
        "   \n",
        "1. [Platform Preperation](#cell_Preperation)     \n",
        "\n",
        "    \n",
        "2. [Data Preperation](#cell_DataPreperation)\n",
        "\n",
        "\n",
        "3. [Deep Learning Model Construction](#cell_Model)\n",
        "\n",
        "\n",
        "4. [Model Execution](#cell_ModelExecution)\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OTV2xnHkVVf"
      },
      "source": [
        "<a id = \"cell_Preperation\"></a>\n",
        "### 1. Platform Preperation\n",
        "\n",
        "Make sure to change Notebook Settings using GPU as hardware accelerator in Google Colab.\n",
        "\n",
        "*Markdown formats: All tables and images will be aligned to the left.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0RPUnibkVVg"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<style>table {float:left}</style>\n",
        "<style>img {float:left}</style>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7hqqv3RkVVg"
      },
      "source": [
        "Load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd-C17FLkVVg"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0k0bdtRkVVh"
      },
      "source": [
        "Check GPUs on this machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMmslexEkVVh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwH-kIPUkVVh"
      },
      "source": [
        "Create a function to plot images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUjYc5ARkVVh"
      },
      "outputs": [],
      "source": [
        "def plot_images(ims, figsize=(12,12), cols=1, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims = ims[:,:,:,0]\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    rows=len(ims)//cols if len(ims) % cols == 0 else len(ims)//cols + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BNUYbjrkVVi"
      },
      "source": [
        "Create a function to plot history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO2wjvG4kVVi"
      },
      "outputs": [],
      "source": [
        "def plot_hist(h, xsize=6, ysize=5):\n",
        "    # Prepare plotting\n",
        "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "    plt.rcParams[\"figure.figsize\"] = [xsize, ysize]\n",
        "\n",
        "    # Get training and validation keys\n",
        "    ks = list(h.keys())\n",
        "    n2 = math.floor(len(ks)/2)\n",
        "    train_keys = ks[0:n2]\n",
        "    valid_keys = ks[n2:2*n2]\n",
        "\n",
        "    # summarize history for different metrics\n",
        "    for i in range(n2):\n",
        "        plt.plot(h[train_keys[i]])\n",
        "        plt.plot(h[valid_keys[i]])\n",
        "        plt.title('Training vs Validation '+train_keys[i])\n",
        "        plt.ylabel(train_keys[i])\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        plt.draw()\n",
        "        plt.show()\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxlfbmcgkVVi"
      },
      "source": [
        "<a id = \"cell_DataPreperation\"></a>\n",
        "### 2. Data Preperation\n",
        "\n",
        "The below codes provide the procedures to load **CIFAR10** data sets. The data set consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yHsHxrBkVVj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Data parameters\n",
        "img_rows, img_cols = 32, 32\n",
        "channels = 3\n",
        "\n",
        "num_classes = 10\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hyXq0fmkVVk"
      },
      "source": [
        "**Prepare the selected data set and split into training and testing sets.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lymRCI39kVVk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Reshape images for processing\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n",
        "\n",
        "# Convert pipxel values to 8 bits\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "print('Train shape: x=', x_train.shape, ', y=', y_train.shape)\n",
        "print('Test shape: x=', x_test.shape, ', y=', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIuLqOixkVVk"
      },
      "source": [
        "Show a sample of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0nVWUJIkVVk"
      },
      "outputs": [],
      "source": [
        "plot_images(x_train[0:20], cols=5,figsize=[7,7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EYK0jy9kVVk"
      },
      "source": [
        "<a id = \"cell_Model\"></a>\n",
        "### 3. Deep Learning Model Construction\n",
        "\n",
        "Load the required libraries for CNN construction  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf1H0p2ckVVk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten\n",
        "from tensorflow.keras.layers import MaxPooling2D, Activation, BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard, Callback, EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam, Nadam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDjWOaKkVVl"
      },
      "source": [
        "Build some models with varied architectures (e.g. layers, nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCOVas4BkVVl"
      },
      "outputs": [],
      "source": [
        "#Traditional ANN with one Flatten layer, one Hidden Layer, and one Output layer\n",
        "#All layers are fully connected following traditional ANN architecture.\n",
        "def model_1():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(img_rows, img_cols, channels)))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCXpNN3xkVVm"
      },
      "outputs": [],
      "source": [
        "#CNN model with two Convolution layers, one Pooling layer with max pooling,\n",
        "#which are stacked on top of a traditional ANN model (with the same architecture as the model 1)\n",
        "def model_2():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                     activation='relu',\n",
        "                     input_shape=(img_rows, img_cols, channels)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zxFYCOckVVn"
      },
      "source": [
        "Define callback to record training performnace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klRPAX5xkVVn",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Keras callbacks (when Tensorboard installed)\n",
        "keras_callbacks = [EarlyStopping(monitor='val_loss', patience=20, verbose=0)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTpMa0ApkVVn"
      },
      "source": [
        "<a id = \"cell_ModelExecution\"></a>\n",
        "### 4. Model Execution\n",
        "\n",
        "We select one of the above models to carry out the experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGZ5g3-FkVVn"
      },
      "outputs": [],
      "source": [
        "model = model_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo2-3Ho3kVVo"
      },
      "source": [
        "Compile and fit the model using `RMSprop` optimizer. <br/>\n",
        "*See optimisers: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJELA95OkVVo",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=RMSprop(learning_rate=0.001,weight_decay=1e-6),\n",
        "              metrics='accuracy')\n",
        "\n",
        "#Other Optimizers that can be used instead of RMSprop\n",
        "#Adadelta(lr=0.001, rho=0.95, epsilon=1e-07)\n",
        "#Adadelta(lr=0.05, rho=0.99, epsilon=1e-07)\n",
        "#Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "\n",
        "hist = model.fit(x_train, y_train,\n",
        "      batch_size=128,\n",
        "      epochs=100,\n",
        "      verbose=2,\n",
        "      validation_data=(x_test, y_test),\n",
        "      validation_split=0.2,\n",
        "      callbacks=keras_callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edtwiaz4kVVo"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7fCyDarkVVo"
      },
      "outputs": [],
      "source": [
        "# Evaluate on training data\n",
        "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print('Train loss:', round(train_score[0], 4))\n",
        "print('Train accuracy:', round(train_score[1], 4), '\\n')\n",
        "\n",
        "# Evaluate on test data\n",
        "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', round(test_score[0], 4))\n",
        "print('Test accuracy:', round(test_score[1], 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pNDCo4gBkVVo"
      },
      "source": [
        "Plot history of learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deUCmbJgkVVo"
      },
      "outputs": [],
      "source": [
        "plot_hist(pd.DataFrame(hist.history))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the **accuracy, precision, recall, f1-score, and support**"
      ],
      "metadata": {
        "id": "EFN7hE8TF5Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Convert the predicted labels to continuous-multioutput format\n",
        "y_pred_continuous = np.round(y_pred)\n",
        "\n",
        "# Convert the predicted labels to multiclass format\n",
        "y_pred_multiclass = np.argmax(y_pred, axis=1)\n",
        "y_test_multiclass = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate the kappa score\n",
        "kappa = cohen_kappa_score(y_test_multiclass, y_pred_multiclass)\n",
        "print(\"The result of Kappa is :\", round(kappa, 3))\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_test_multiclass, y_pred_multiclass, target_names= class_names)\n",
        "\n",
        "# Print the report\n",
        "print(\"The result of the classification report is: \\n \",report)"
      ],
      "metadata": {
        "id": "HDvXvYltF4sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "yGDsd0PLG4x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Confusion Matrix for inspection."
      ],
      "metadata": {
        "id": "DeXBsGdkFw3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(\n",
        "    y_test_multiclass,\n",
        "    y_pred_multiclass)\n",
        "\n",
        "# Create a ConfusionMatrixDisplay object\n",
        "display = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm,\n",
        "    display_labels=class_names)\n",
        "\n",
        "# Create a figure with a larger size\n",
        "fig = plt.figure(figsize=(11, 11))\n",
        "\n",
        "# Create a subplot within the figure\n",
        "ax = fig.subplots()\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "display.plot(ax=ax)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "327hqmz4FwRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4Np1_dQkVVp"
      },
      "source": [
        "Print sample predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5cn0ZMdkVVp"
      },
      "outputs": [],
      "source": [
        "img_range = range(20)\n",
        "imgs = x_test[img_range]\n",
        "true_labels = [class_names[np.argmax(x)] for x in y_test[img_range]]\n",
        "predictions = model.predict(imgs.reshape(len(img_range), img_rows, img_cols, channels))\n",
        "pred_labels = [class_names[np.argmax(x)] for x in predictions]\n",
        "titles = [pred_labels[x]+('' if true_labels[x] == pred_labels[x] else ' ('+true_labels[x]+')') for x in img_range]\n",
        "plot_images(imgs, cols=5, figsize=(11,11), titles=titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs4D-NmtkVVp"
      },
      "source": [
        "Save the experiment results on to your computer. Repeat the above experiment with `model_2`. Compare the experiment results between the models. Was the preformance improved with `model_2`? and why?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}