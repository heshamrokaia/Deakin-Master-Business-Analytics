{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrOi_QFRkVVa"
      },
      "source": [
        "# MIS780 - Advanced Artificial Intelligence for Business\n",
        "\n",
        "## Week 5 - Part 2: Dealing with real digital photos\n",
        "\n",
        "In this session, you will practice classify real digital photos with CNN deep learning packages (Tensorflow and Keras)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxnHUSM3kVVf"
      },
      "source": [
        "To do:\n",
        "\n",
        "*  [Task 1.1. Data Loading and Exploration](#cell_1.1)\n",
        "*  [Task 1.2. Practise: CNN Training and Evaluation with the real digital photos](#cell_1.2)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxlfbmcgkVVi"
      },
      "source": [
        "<a id = \"cell_1.1\"></a>\n",
        "## Task 1.1. Data Loading and Exploration\n",
        "\n",
        "In this task, we will download the images from CloudDeakin and upload them to your own `Google Drive` and then import them on your Google Colab Jupyter Notebook.\n",
        "\n",
        "Those given color images are divided into two folders, `city` and `country`. Each folder has 200 color images.\n",
        "\n",
        "First, we load some basic Python libraries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "id": "38jNnkz8fMLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlZb6Q3yDq24"
      },
      "source": [
        "For this lab, we upload images in the two folders to Google Drive. We create a folder named as `dataset` in your Google Drive. Its target path should be \"/My Drive/Colab Notebooks/dataset/\". After that, we upload two folders,`city` and `country` under the `dataset`.\n",
        "\n",
        "Now, we can import those images on Google Colab by below codes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aADNlnYAD8DA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "#it will open a webpage for verifying your google account. if it is successful, the Google colab can link the Google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# to show the folders under the dataset\n",
        "!ls \"/content/drive/My Drive/Colab Notebooks/dataset/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqDA8s67HNkE"
      },
      "source": [
        "We check the total number of files under the `City` folder and `Country`, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o2L8mYHHNtZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the paths to the folders containing the image files\n",
        "city_path = '/content/drive/MyDrive/Colab Notebooks/dataset/City'\n",
        "country_path = '/content/drive/MyDrive/Colab Notebooks/dataset/Country'\n",
        "\n",
        "# get a list of all files in the folder\n",
        "city_file_list = os.listdir(city_path)\n",
        "country_file_list = os.listdir(country_path)\n",
        "\n",
        "# print the total number of files\n",
        "print(f'Total number of files under city folder are: {len(city_file_list)}')\n",
        "print(f'Total number of files under country folder are: {len(country_file_list)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLOGD6_ndN1l"
      },
      "source": [
        "We read raw data under two folders and decode it into a tensor by `TensorFlow`. Each file is assigned a label based on which folder it is in. The images are also resized to a 100x100 resolution using the resize function. Image data and labels are stored in a list called `data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOl75C7L--st"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a list to store the image data and labels\n",
        "data = []\n",
        "\n",
        "# Iterate through the files in the first folder\n",
        "for file in os.listdir(city_path):\n",
        "  # Check if the file is a jpeg or jpg file\n",
        "  if file.endswith('.jpeg') or file.endswith('.jpg'):\n",
        "    # Load the image data from the file using TensorFlow\n",
        "    img = tf.io.read_file(os.path.join(city_path, file))\n",
        "    img = tf.image.decode_jpeg(img,channels=3)\n",
        "    img = tf.image.resize(img, (50, 50))\n",
        "    # Assign a label to the file\n",
        "    label = 'City'\n",
        "    # Add the image data and label to the data list\n",
        "    data.append((img, label))\n",
        "\n",
        "# Iterate through the files in the second folder\n",
        "for file in os.listdir(country_path):\n",
        "  # Check if the file is a jpeg or jpg file\n",
        "  if file.endswith('.jpeg') or file.endswith('.jpg'):\n",
        "    # Load the image data from the file using TensorFlow\n",
        "    img = tf.io.read_file(os.path.join(country_path, file))\n",
        "    img = tf.image.decode_jpeg(img,channels=3)\n",
        "    img = tf.image.resize(img, (50, 50))\n",
        "    # Assign a label to the file\n",
        "    label = 'Country'\n",
        "    # Add the image data and label to the data list\n",
        "    data.append((img, label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ghinIjeRkC"
      },
      "source": [
        "The data is shuffled and split into a training set and a test set using list slicing. The training set consists of the first 80% of the data, and the test set consists of the remaining 20%."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data and split into train/test sets\n",
        "random.shuffle(data)\n",
        "train_data, test_data = data[:int(len(data) * 0.8)], data[int(len(data) * 0.8):]"
      ],
      "metadata": {
        "id": "OQ4LHyRNeKAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1rUbcxBmy3q"
      },
      "source": [
        "We allocate X_train, X_test, Y_train, and Y_test and convert them into NumPy arrays for later CNN module training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inh94Zm_ABbA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Extract the image data and labels from the training data\n",
        "X_train, Y_train = zip(*train_data)\n",
        "\n",
        "# Extract the image data and labels from the testing data\n",
        "X_test, Y_test = zip(*test_data)\n",
        "\n",
        "# Convert the image data and labels into NumPy arrays\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgqKXVqDncje"
      },
      "source": [
        "We normalize the input data, the X_train and X_test, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHR-wn3vF7Lr"
      },
      "outputs": [],
      "source": [
        "# change integers to 32-bit floating point numbers\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalize each value for each pixel for the entire vector for each input\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# print the shape of the reshaped data\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj7Tc10AntYq"
      },
      "source": [
        "We apply the unique integer mapping encoding for the two classes, `City` and `Country`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpjMWTQyGb-H"
      },
      "outputs": [],
      "source": [
        "print('The original format of class of the first element in the training dataset is: ',Y_train[0], '\\n')\n",
        "\n",
        "import numpy as np\n",
        "# Create a NumPy array with category strings\n",
        "categories = np.array(['City', 'Country'])\n",
        "\n",
        "# Create a mapping from category strings to integers\n",
        "category_map = {'City': 0, 'Country': 1}\n",
        "\n",
        "# Encode the categories\n",
        "Y_train = np.array([category_map[category] for category in Y_train])\n",
        "Y_test = np.array([category_map[category] for category in Y_test])\n",
        "\n",
        "print('The unique integer mapping encoding format of the calss of the first element in the training dataset is: ',Y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPitp2oSNH4H"
      },
      "source": [
        "We plot some color images from the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0nVWUJIkVVk"
      },
      "outputs": [],
      "source": [
        "# change the default figure size for all plots created in the program\n",
        "plt.rcParams['figure.figsize'] = (9,9)\n",
        "\n",
        "labels =  ['City', 'Country']\n",
        "\n",
        "for i in range(25):\n",
        "    # plt.subplot() function takes three integer arguments: the number of rows, the number of columns, and the index of the subplot.\n",
        "    plt.subplot(5,5,i+1)\n",
        "    # plt.imshow() function displays the image at index i in the X_train array as a grayscale image, with no interpolation applied.\n",
        "    plt.imshow(X_train[i], interpolation='none')\n",
        "    plt.title(\"{}\".format(labels[int(Y_train[i])]))\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcpDx02aQRLS"
      },
      "source": [
        "<a id = \"cell_1.2\"></a>\n",
        "## Task 1.2. Practise: CNN Training and Evaluation with the real digital photos\n",
        "\n",
        "Apply the CNN model to classify the photos and evaluate the model.  You can refer workshop materials in the Part 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code from here"
      ],
      "metadata": {
        "id": "Tff2XybA-TvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}