<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager --><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager --><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>CloudDeakin Dual Delivery Template</title>
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-fl.css">
  <link rel="stylesheet" type="text/css" href="../00-assets/navbar/navbar-parent.css">
<link rel="stylesheet" type="text/css" href="../00-assets/css/sit307-720.css">

</head><body class="cloudFirst"><p style="text-align: center;"><img src="../images/Supervised%20learning%20overview%20image%201.jpg" alt="Paper and Data Composing Red, Blue and Yellow Graph Directly Above View" title="Paper and Data Composing Red, Blue and Yellow Graph Directly Above View" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<address><a href="https://www.gettyimages.com.au" target="_blank" rel="noopener noreferrer">© Getty Images</a></address><hr>
<h1>Supervised learning overview</h1>
<div>
<p>The majority of practical ML uses supervised learning.</p>
<p>This brief overview will give you a broad understanding of supervised learning. It’s an important concept and we’ll be going into much more detail in the up coming weeks.</p>
<p>What is supervised learning?</p>
<p>Supervised learning can be defined as:<br><strong>learning a function (otherwise known as a model) from data to relate inputs to known outputs</strong>.</p>
<p>If the concept is unfamiliar it may take several different descriptions or definitions to make sense of the idea.</p>
<h3 id="supervised-learning-is-trained">Supervised learning is trained</h3>
<p>One defining characteristic of supervised learning is that datasets have relationships built in from the start.</p>
<p>For example, if you have datasets on vehicles you know that most cars have four wheels while most bicycles have two. You could say that having two wheels is a function of being a bicycle (with some exceptions) and having four wheels is a function of being a car (with the exception of very rare <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Fuldamobil_S-7_at_Schaffen-Diest_2018.jpg/280px-Fuldamobil_S-7_at_Schaffen-Diest_2018.jpg" target="_blank" rel="noopener noreferrer">three-wheeled cars like this Fuldamobil S-7</a>).</p>
<p>This makes it possible to&nbsp;<em>train</em>&nbsp;the algorithm. The machine learns using known relationships in the data.</p>
<h3 id="training-and-evaluation-data">Training and evaluation data</h3>
<p>For supervised learning, training requires dividing the available data into&nbsp;<em>training data</em>&nbsp;and&nbsp;<em>evaluation data</em>. Most of the data is used to develop and train a function ‘model’. We know the relationship between the inputs and the outputs. In other words, we know the ‘right’ answers so we can select, manipulate and refine features to train the machine. The more often the answer is correct, (ie. “This is a bicycle”), the closer you are to having a useful algorithm.</p>
<p>The evaluation data can be used to test the model with fresh, unused input data.</p>
<h3 id="a-mathematical-definition">A mathematical definition</h3>
<p>Machine algorithms must be described mathematically. Remember that computers understand numbers so we must translate our questions into formulas or algorithms so they can process answers.</p>
<p>In&nbsp;<em>supervised learning</em>, the training data includes output information (labels/targets).</p>
<ul>
<ul>
<li><strong>Target function:&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>f</mi><mo>:</mo><mi>X</mi><mo stretchy="false">→<!-- → --></mo><mi>Y</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(f: X \rightarrow Y\)"}</annotation></semantics></math></strong></li>
<li><strong>Examples:&nbsp;</strong>It is in the form of<strong>&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\((x,y)\)"}</annotation></semantics></math>, </strong>denoted as<strong>&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\((x_1,y_1)\)"}</annotation></semantics></math>,&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo>.</mo><mo>.</mo><mo>.</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(...\)"}</annotation></semantics></math>,&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo>,</mo><msub><mi>y</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\((x_n , y_n)\)"}</annotation></semantics></math>.</strong></li>
<li><strong>Hypothesis&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>g</mi><mo>:</mo><mi>X</mi><mo stretchy="false">→<!-- → --></mo><mi>Y</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(g: X \rightarrow Y\)"}</annotation></semantics></math>&nbsp;</strong>such that<strong>&nbsp;&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(g(x) = f(x)\)"}</annotation></semantics></math>.</strong></li>
<li>x = set of attribute values (<strong>attribute-value representation</strong>).</li>
<li>y = a discrete label (<em>classification</em>), a real valued number (<em>regression</em>).</li>
</ul>
</ul>
<h3 id="two-types-of-supervised-learning">Two types of supervised learning</h3>
<ul>
<ul>
<ol>
<li>Classification problems</li>
</ol>
</ul>
</ul>
<p>In a supervised learning problem with two classes,&nbsp;<em>decision boundaries</em>&nbsp;are a hyper-surface that partitions data space into two sets, each of these sets represent one of the classes. In other words, you divide the data according to a trained algorithm.</p>
<p>Consider the following figure as an illustration of supervised learning.</p>
<p class="centerImage"><img src="../images/Supervised%20learning%20overview%20image%202.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5 id="figure-supervised-learning-with-linear-decision-boundary-vs-non-linear-decision-boundary">Figure. Supervised learning, with linear decision boundary vs non-linear decision boundary.</h5>
<p>As you can see on the left, in some less complex cases a linear decision boundary can solve the classification problem. However as illustrated on the right, more complex cases, require complicated decision boundaries.</p>
<p>This video describes ML and the classification problem in more detail. Make sure you have a good overview of this concept before you keep going (we will also be coming back to this topic later).</p>
<div>
<p></p>
<p class="centerVideo"><iframe width="648" height="365" src="https://www.youtube.com/embed/nKW8Ndu7Mjw?wmode=opaque" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>
<h5>This is an additional video, hosted on YouTube</h5>
</div>
<p></p>
<p style="padding-left: 360px;">2. Regression problems</p>
<p>Another example of supervised learning, is&nbsp;<em>regression</em>. The overall idea of regression is to examine the relationship between response variables and one or more predictor variables. This examination can result in a hyperplane, representing the regression analysis. The following figure, illustrates a regression problem in 2 dimensions.</p>
<p class="centerImage"><img src="../images/Supervised%20learning%20overview%20image%203.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5 id="figure-regression-problem-in-2-dimensions-x1-and-x2">Figure. Regression problem in 2 dimensions (<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>X</mi><mn>1</mn></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(X_1\)"}</annotation></semantics></math>&nbsp;and&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>X</mi><mn>2</mn></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(X_2\)"}</annotation></semantics></math>).</h5>
<h1 id="your-task"><span style="color: rgb(96, 56, 255);">Activity</span></h1>
<p>Do some research and provide a real-life example of machine learning that uses supervised learning.&nbsp;</p>
<p>Share your response in the <a href="/d2l/common/dialogs/quickLink/quickLink.d2l?ou=1734011&amp;type=discuss&amp;rcode=DeakinUniv-19277" target="_self">Student Discussion</a>.</p>
<ul></ul>
</div>
<hr>
<div><iframe class="quickNavStyle" scrolling="no" src="../00-assets/navbar/navbar.html" title="NavBar" allowfullscreen="allowfullscreen" frameborder="0"></iframe></div>
<!-- <div style="padding-top: 20px;"><a href="#" class="navrep-button" target="_parent" title="Previous" style="padding: .5rem .5rem; font-size: 12pt; float: left;"> &lt; Previous</a> <a href="#" class="navrep-button" target="_parent" title="Next" style="padding: .5rem .5rem; font-size: 12pt; float: right;">Next &gt;</a></div>
<p style="padding-bottom: 50px;"></p>
</div> -->
<p>
<script defer="defer" type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-master.js"></script>
</p>
<p>
<script>
function localProc(){
  console.log("ready!");
}
</script>
</p>
<p>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-sebe-lst-learning-design/fl-dual-delivery/js/sebe-fl-nav.js"></script>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-sebe-lst-learning-design/fl-dual-delivery/js/sebe-fl.js"></script>
<script src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/jquery/jquery_3_5_1/jquery-3.5.1.min.js"></script>
<script src="../00-assets/navbar/navbar-parent.js"></script>
<script src="../00-assets/js/sit307-720.js"></script>
</p></body></html>