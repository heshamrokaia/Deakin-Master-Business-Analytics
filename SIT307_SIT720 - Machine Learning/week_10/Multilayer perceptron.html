<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager --><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager --><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>CloudDeakin Dual Delivery Template</title>
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-fl.css">
  <link rel="stylesheet" type="text/css" href="../00-assets/navbar/navbar-parent.css">
<link rel="stylesheet" type="text/css" href="../00-assets/css/sit307-720.css">

<link rel="stylesheet" href="https://s.brightspace.com/lib/fonts/0.5.0/fonts.css"></head><body style="color: rgb(32, 33, 34); font-family: verdana, sans-serif; font-size: 10px;"><p><img src="../images/Multilayer%20perceptron%20image%201.jpg" alt="Rainbow cake" title="Rainbow cake" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<address><a href="https://www.gettyimages.com.au" target="_blank" rel="noopener noreferrer">© Getty Images</a></address>
<div>
<h1>Multilayer perceptron</h1>
</div>
<div style="padding-left: 30px;">
<p>A perceptron is quite weak in what it can represent. For complex, non-linear decision surfaces, we need a multi-layer network.</p>
<p>If you remember the&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>s</mi><mi>i</mi><mi>g</mi><mi>n</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(sign\)"}</annotation></semantics></math>&nbsp;function in a perceptron, we are had a<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo>−<!-- − --></mo><mn>1</mn><mo>,</mo><mn>1</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(-1,1\)"}</annotation></semantics></math>&nbsp; (binary) output but choosing a more complex&nbsp;<em>activation function</em>&nbsp;allows the network to combine the inputs in more complex ways and in turn provides a richer capability in the functions they can model.</p>
<p>Non-linear functions like the logistic, (also called the&nbsp;<em>sigmoid function</em>), output a value between&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mn>0</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(0\)"}</annotation></semantics></math>&nbsp;and&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mn>1</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(1\)"}</annotation></semantics></math>&nbsp;with an s-shaped distribution. Choice of node in a multi-layer network should be continuous but it should be a continuous&nbsp;<em>meaningful</em>&nbsp;function such as the sigmoid function.</p>
<p>It may sound complicated but it’s quite simple; like a perceptron we have a function, but this time it is a sigmoid function&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>σ<!-- σ --></mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mo>−<!-- − --></mo><mi>Z</mi></mrow></msup><msup><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo>−<!-- − --></mo><mn>1</mn></mrow></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\sigma(Z) = (1+e^{-Z})^{-1}\)"}</annotation></semantics></math>&nbsp;and&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>y</mi><mo>=</mo><mi>σ<!-- σ --></mi><mo stretchy="false">(</mo><msup><mrow class="MJX-TeXAtom-ORD"><mi>w</mi></mrow><mi>T</mi></msup><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(y=\sigma({w}^T{x})\)"}</annotation></semantics></math>&nbsp;instead of the sign function such as&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>y</mi><mo>=</mo><mi>s</mi><mi>i</mi><mi>g</mi><mi>n</mi><mo stretchy="false">(</mo><msup><mrow class="MJX-TeXAtom-ORD"><mi>w</mi></mrow><mi>T</mi></msup><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(y = sign({w}^T{x})\)"}</annotation></semantics></math>.&nbsp;Check the following figure for summarizing the points we have proposed. In this figure we have also calculated the first derivative of the sigmoid function.&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mfrac><mrow><mi>d</mi><mi>σ<!-- σ --></mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo></mrow><mrow><mi>d</mi><mi>Z</mi></mrow></mfrac></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\frac{d\sigma(Z)}{dZ}\)"}</annotation></semantics></math>.&nbsp;</p>
<p>Later this is useful to know! It could be good practice to calculate the derivative by yourself.</p>
<p class="centerImage"><img src="../images/Multilayer%20perceptron%20image%202.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5>Figure.&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>s</mi><mi>i</mi><mi>g</mi><mi>n</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(sign\)"}</annotation></semantics></math>&nbsp;function or a&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(sigmoid\)"}</annotation></semantics></math>&nbsp;function.&nbsp;</h5>
<h3 id="feedforward-neural-networks">Feedforward neural networks</h3>
<p>A&nbsp;<em>feedforward neural network</em>&nbsp;is an&nbsp;<em>Artificial Neural Network</em>&nbsp;(ANN) where connections between units do not form a cycle. In this network, the information moves in only one direction,&nbsp;<em>forward</em>, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.</p>
<p>A multi-layer feed-forward Neural Network (NN) is also known as a&nbsp;<em>Multi-layer Perceptron</em>&nbsp;(MLP). The term MLP is really an accurate name because the model comprises multiple layers of logistic regression like models (with continuous non-linearities) rather than multiple perceptrons (with discontinuous non-linearities). Although this may not be a good choice, we will continue using the term MLP!</p>
<h3 id="notes-on-the-mlp">Notes on the MLP</h3>
<p>Consider a two-layer network: input layer, hidden layer and output layer (see figure below).</p>
<p class="centerImage"><img src="../images/Multilayer%20perceptron%20image%203.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5>Figure. Two-layer neural network.</h5>
<p>There are some really important facts about this network you should consider:</p>
<ul style="font-size: 0.95rem;">
<li>the output is a vector</li>
<li>there are two kinds of weights here:
<ul>
<li>input → hidden</li>
<li>hidden → output</li>
</ul>
</li>
<li><span style="font-size: 15.2px;"><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msubsup><mi>w</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mi>j</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>h</mi></mrow></msubsup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(w_{ij}^{h}\)"}</annotation></semantics></math>&nbsp;from&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msup><mi>i</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>h</mi></mrow></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(i^{th}\)"}</annotation></semantics></math>&nbsp;input&nbsp;→&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msup><mi>j</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>h</mi></mrow></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(j^{th}\)"}</annotation></semantics></math>&nbsp;hidden</span></li>
<li><span style="font-size: 15.2px;"><span style="font-size: 15.2px;"><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msubsup><mi>w</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mi>j</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>o</mi></mrow></msubsup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(w_{ij}^{o}\)"}</annotation></semantics></math>&nbsp;from&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msup><mi>j</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>h</mi></mrow></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(j^{th}\)"}</annotation></semantics></math>&nbsp;hidden&nbsp;→&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msup><mi>k</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>h</mi></mrow></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(k^{th}\)"}</annotation></semantics></math>&nbsp;</span></span><span style="font-family: Lato, sans-serif; font-size: 0.95rem;">output</span></li>
<li>the input layer does no computation - it only relays the input vector</li>
<li>it can have more than one hidden layer</li>
<li>another interesting feature is that it does not have to be fully connected.</li>
</ul>
<p>Though it looks to be a simple structure and mode, later we can see how powerful it is. The figure below shows one of the early applications of ANNs in image processing and self-driving cars! The output of this ANN, as you would expect, is the degree of steering in a particular direction.</p>
<p class="centerImage"><img src="../images/Multilayer%20perceptron%20image%204.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5>Figure. <a href="https://www.cs.ubbcluj.ro/~gabis/ml/ml-books/McGrawHill%20-%20Machine%20Learning%20-Tom%20Mitchell.pdf" target="_blank" rel="noopener noreferrer">Early stages of ANNs</a>: Using ANN for computer vision applications.</h5>
<h3 id="mlp-formulation">MLP Formulation</h3>
<p>Now we explore the formulations behind the MLP. Consider the ANN from you before.</p>
<p class="centerImage"><img src="../images/Multilayer%20perceptron%20image%205.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5><br>Figure. Two-layer neural network.</h5>
<p>Given input&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>x</mi><mi>t</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(x_t\)"}</annotation></semantics></math>&nbsp;and desired output&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mi>t</mi></msub><mo>,</mo><mtext>&nbsp;</mtext><mtext>&nbsp;</mtext><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>…<!-- … --></mo><mo>,</mo><mi>n</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\({y}_t, \ \ t=1,\dots,n\)"}</annotation></semantics></math>&nbsp;the aim is to find the network weights&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>w</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(w\)"}</annotation></semantics></math>&nbsp;so that the predicted values will be as close as possible to the real ones.</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mover><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mo stretchy="false">^<!-- ^ --></mo></mover></mrow><mi>t</mi></msub><mo>≈<!-- ≈ --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mi>t</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\hat{y}_t \approx{y}_t\)"}</annotation></semantics></math>&nbsp;</p>
<p>In other words, we would like to minimise the error which is the difference of the predicted value compared to the real true value of the output. We are stating the above as an optimisation problem: find&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>w</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(w\)"}</annotation></semantics></math>to minimise the error function:</p>
<p class="centerImage"><img src="../images/Multilayer%20perceptron%20image%206.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5>Figure: An example of gradient-descent minimization</h5>
<p>In this case, we will use gradient-descent for minimisation.&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>E</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>w</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(E({w})\)"}</annotation></semantics></math>&nbsp;is not convex, rather it is a complex function with potentially many local minima. For solving this problem, we will use an algorithm called Backpropagation. Before we go through Backpropagation, let’s first remind you of the important concepts about&nbsp;<em>Gradient-based Optimization</em></p>
<h3 id="detour-gradient-based-optimization">Detour: Gradient-based Optimization</h3>
<p>Gradient-based optimisation methods are operated with the search directions defined by the gradient of the function at the current point. Consider the following figure as a&nbsp;<em>convex function</em>.</p>
<p class="centerImage"><img src="../images/Multilayer%20perceptron%20image%207.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5>Figure. Example of a convex function.</h5>
<p>At a point in&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mn>2</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(2\)"}</annotation></semantics></math>D such as&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo>=</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\({x} = (x_1,x_2)\)"}</annotation></semantics></math>,&nbsp;the gradient vector of the function&nbsp;&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>f</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(f({x})\)"}</annotation></semantics></math>,&nbsp;&nbsp;w.r.t&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>x</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(x\) "}</annotation></semantics></math>&nbsp;is:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi mathvariant="normal">∇<!-- ∇ --></mi><mi>f</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mo maxsize="1.623em" minsize="1.623em">(</mo></mrow><mfrac><mrow><mi mathvariant="normal">∂<!-- ∂ --></mi><mi>f</mi></mrow><mrow><mi mathvariant="normal">∂<!-- ∂ --></mi><msub><mi>x</mi><mn>1</mn></msub></mrow></mfrac><mo>,</mo><mfrac><mrow><mi mathvariant="normal">∂<!-- ∂ --></mi><mi>f</mi></mrow><mrow><mi mathvariant="normal">∂<!-- ∂ --></mi><msub><mi>x</mi><mn>2</mn></msub></mrow></mfrac><mrow class="MJX-TeXAtom-ORD"><mo maxsize="1.623em" minsize="1.623em">)</mo></mrow></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\nabla f({x}) = \Big(\frac{\partial f}{\partial x_1},\frac{\partial f}{\partial x_2} \Big)\)"}</annotation></semantics></math>&nbsp;</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi mathvariant="normal">∇<!-- ∇ --></mi><mi>f</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\nabla f({x})\)"}</annotation></semantics></math>&nbsp;represents the&nbsp;<em>direction</em>&nbsp;that produces the steepest increase in&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>f</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(f\)"}</annotation></semantics></math>.&nbsp; Similarly&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo>−<!-- − --></mo><mi mathvariant="normal">∇<!-- ∇ --></mi><mi>f</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(-\nabla f({x})\)"}</annotation></semantics></math>&nbsp;is the direction of the steepest decrease in&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>f</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(f\)"}</annotation></semantics></math>.&nbsp;So to minimise a function such as&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>f</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(f({x})\)"}</annotation></semantics></math>,&nbsp;we should use gradient-descent using the following steps:</p>
<ol>
<li>Initialise random&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mn>0</mn></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\({x}_0\)"}</annotation></semantics></math></li>
<li>Slide down the surface of&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>f</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(f\)"}</annotation></semantics></math>&nbsp;in the direction of the&nbsp;<em>steepest decrease</em>:</li>
</ol>
<span style="font-size: 15.2px;"><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub><mo>−<!-- − --></mo><mi>η<!-- η --></mi><mo>×<!-- × --></mo><mi mathvariant="normal">∇<!-- ∇ --></mi><mi>f</mi><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\({x}_{t+1} = {x}_t - \eta \times \nabla f({x}_t)\)"}</annotation></semantics></math></span></div>
<div style="padding-left: 30px;">
<p>Based on previous explanations on maximising the function&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>f</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(f\)"}</annotation></semantics></math>,&nbsp;you can use a similar method to maximise&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>f</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(f({x})\)"}</annotation></semantics></math>&nbsp;ie. use gradient-ascent as:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub><mo>+</mo><mi>η<!-- η --></mi><mo>×<!-- × --></mo><mi mathvariant="normal">∇<!-- ∇ --></mi><mi>f</mi><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\({x}_{t+1} = {x}_t + \eta \times \nabla f({x}_t)\)"}</annotation></semantics></math></p>
<p>By finding the true direction towards the optimal point and the magnitude of the movement towards it, gradient-descent finds the optimal point. It is a very useful approach even in ANNs. The following figure illustrates an example of the gradient-descent method on the sample convex function.</p>
<p class="centerImage"><img src="../images/Multilayer%20perceptron%20image%208.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5><br>Figure. How Gradient-Descent works from&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>x</mi><mn>0</mn></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(x_0\)"}</annotation></semantics></math>&nbsp;to minimum point&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msup><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mo>∗<!-- ∗ --></mo></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\({x}^*\)"}</annotation></semantics></math></h5>
<p>If we incorporate this idea in the error function we had before, we can minimise the error value between the true output and the predicted one in each iteration. Remember that we defined&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>E</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>w</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(E({w})\)"}</annotation></semantics></math>&nbsp;the error function, as:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>E</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>w</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><munderover><mo>∑<!-- ∑ --></mo><mrow class="MJX-TeXAtom-ORD"><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>K</mi></mrow></munderover><mo stretchy="false">(</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>k</mi></mrow></msub><mo>−<!-- − --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mover><mi>y</mi><mo stretchy="false">^<!-- ^ --></mo></mover></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>k</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(E_t({w}) = \frac{1}{2} \sum_{k=1}^{K} (y_{tk} - \hat{y}_{tk})^2\)"}</annotation></semantics></math>&nbsp;</p>
<p>Based on the gradient-descent, for minimising this function we need an&nbsp;<em>update rule</em>&nbsp;(where&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>t</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(t\)"}</annotation></semantics></math>&nbsp;denotes the current training sample) which is:</p>
<p>&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">←<!-- ← --></mo><msub><mi>w</mi><mi>i</mi></msub><mo>−<!-- − --></mo><mi>η<!-- η --></mi><mfrac><mrow><mi mathvariant="normal">∂<!-- ∂ --></mi><msub><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi></mrow></msub><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>w</mi></mrow><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂<!-- ∂ --></mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>w</mi></mrow><mi>i</mi></msub></mrow></mfrac></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(w_i \leftarrow w_i - \eta \frac{\partial E_{t} ({w})}{\partial {w}_i}\)"}</annotation></semantics></math></p>
<p>So instead of minimising&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>E</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>w</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(E({w})\)"}</annotation></semantics></math>,&nbsp;the&nbsp;<em>Stochastic Gradient-Descent</em>&nbsp;(SGD) minimises the instantaneous approximation&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>E</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi>w</mi></mrow><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(E({w})\)"}</annotation></semantics></math> of&nbsp;&nbsp;using only the&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>t</mi><mo>−<!-- − --></mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(t-\)"}</annotation></semantics></math>th instance. SGD is cheap to perform and guaranteed to reach a local minimum in a stochastic sense.</p>
<p>Now that you have an understanding of gradient-descent, it is time to move to the Backpropagation algorithm.</p>
<h2 id="your-task">Activity</h2>
<p>Watch this interesting tutorial on Neural Networks and let us know your thoughts in the <a href="/d2l/common/dialogs/quickLink/quickLink.d2l?ou=1734011&amp;type=discuss&amp;rcode=DeakinUniversity-2003941" target="_top">discussion forum</a>.</p>
<p></p>
<div>
<p class="centerVideo"><iframe width="648" height="364" src="https://www.youtube.com/embed/u5GAVdLQyIg?wmode=opaque" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>
<h5>This is an additional video, hosted on YouTube.</h5>
</div>
<p></p>
</div>
<hr>
<div><iframe class="quickNavStyle" scrolling="no" src="../00-assets/navbar/navbar.html" title="NavBar" allowfullscreen="allowfullscreen" frameborder="0"></iframe></div>
<!-- <div style="padding-top: 20px;"><a href="#" class="navrep-button" target="_parent" title="Previous" style="padding: .5rem .5rem; font-size: 12pt; float: left;"> &lt; Previous</a> <a href="#" class="navrep-button" target="_parent" title="Next" style="padding: .5rem .5rem; font-size: 12pt; float: right;">Next &gt;</a></div>
<p style="padding-bottom: 50px;"></p>
</div> -->
<p>
<script defer="defer" type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-master.js"></script>
</p>
<p>
<script>
function localProc(){
  console.log("ready!");
}
</script>
</p>
<p>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-sebe-lst-learning-design/fl-dual-delivery/js/sebe-fl-nav.js"></script>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-sebe-lst-learning-design/fl-dual-delivery/js/sebe-fl.js"></script>
<script src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/jquery/jquery_3_5_1/jquery-3.5.1.min.js"></script>
<script src="../00-assets/navbar/navbar-parent.js"></script>
<script src="../00-assets/js/sit307-720.js"></script>
</p></body></html>