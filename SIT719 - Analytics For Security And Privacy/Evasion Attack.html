<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>SEBE Template</title>
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-fl.css">
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/open-source-css-and-js/prism/prism.css">
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/open-source-css-and-js/prism/prism.overrides.css">
</head><body class="cloudFirst"><h1>Evasion Attack</h1>
<!-- ------------------------------------------- -->
<h2 style="text-align: center;"><span style="color: #cf2a27;">&nbsp;<iframe src="/d2l/common/dialogs/quickLink/quickLink.d2l?ou=1545175&amp;type=lti&amp;rCode=DeakinUniversity-4669589" title="EvasionAttack" allowfullscreen="allowfullscreen" allow="microphone *; camera *; autoplay *" height="405" width="720"></iframe></span></h2>
<p>Exploiting&nbsp;adversarial space to find adversarial examples that cause a misclassification in a machine learning classifier is called an&nbsp;<i>evasion attack</i>. Evasion attacks&nbsp;are the most popular kind of attack that may be incurred in adversarial settings during system operation.&nbsp;For instance, spammers and hackers often attempt to evade detection by obfuscating the content of spam emails and malware code.&nbsp;In the evasion setting, malicious samples are modified at test time to evade detection, that is, to be misclassified as legitimate.&nbsp;No influence over the training data is possible.&nbsp;</p>
<p>Evasion attacks are worthy of concern because they are more generally applicable than poisoning attacks. For one, these attacks can affect&nbsp;<i>any</i>&nbsp;classifier, even if the user has no influence over the training phase. In combination with the phenomenon of adversarial transferability and local substitute model training, the exploratory nature of this technique means that motivated attackers can launch highly targeted attacks on the integrity of a large class of machine learning systems. Evasion attacks with adversarial examples have been shown to have a significant impact on both traditional machine learning models (logistic regression, SVMs, nearest neighbor, decision trees, etc.) and deep learning models.</p>
<p>&nbsp;</p>
<p></p>
<p>
<script defer="defer" type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-master.js"></script>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/open-source-css-and-js/prism/prism.js"></script>
</p>
<p><script>
function localFunction(){

  console.log("");
  console.log("ready!");

 
  /* ------------------------------------------------ */  
  /* -- START: PRISM JS PRINT LANGUAGES TO CONSOLE -- */
  var p = Prism.languages;
  var languagesArray = new Array();

  // iterate over elements in Prism.languages
  console.log("")
  console.log("Iterating over Prism.languages object...");
  for (var key in p) {
    if (p.hasOwnProperty(key)) {
      // if an element is a function, ignore it
      if ( p[key] instanceof Function ) {
        console.log("found function: " + key);
      } else {
        // otherwise if it's an object, count it as language
        languagesArray.push(key);
      }
    }
  }
  console.log("");

  var languagesString = "";
  var counter = 0;
  console.log("Found " + languagesArray.length + " languages in the Prism.languages object");
  languagesArray.sort().forEach(function (language) {
    languagesString += language;
    if(++counter < languagesArray.length) {
      languagesString += ", ";
    }
  });

  console.log("List of languages available:");
  console.log("--------------------------------------");
  console.log(languagesString);
  console.log("--------------------------------------");
  /* -- END:   PRISM JS PRINT LANGUAGES TO CONSOLE -- */
  /* ------------------------------------------------ */  

  $('#viewTranscript').click(function(){
    if($('#viewTranscript').text() == 'View transcript') {
      $('#transcript-en').show();
      $('#viewTranscript').text('Close transcript');
    } else {
      $('#transcript-en').hide();
      $('#viewTranscript').text('View transcript');
    }
  });
 
  /* Just need 3 things in the markup: 1. href="#video1", 2. class="transcript__timestamp" and 3. the timestamp value eg. 2:47  */
 $(".transcript__timestamp").click(function(){

    //collect video id and time attributes

      //var thisID = $(this).attr('id');
      var thisHref = $(this).attr('href');
      //the href is an id but will strp the # of it in case that's not always what the id is. Thsi hash can be added back oin the global func
      thisHref = thisHref.substring(1);
      //console.log(thisHref);
      var thisTimsStr = $(this).text();

      //thisTimsStr may have extra text after the actual time so to make sure, it needs to be stripped out.
      var n = thisTimsStr.indexOf(":")+3;
      var stripped = thisTimsStr.substring(0, n);
      //console.log('stripped '+ stripped);
      //now convert to seconds
      var split = stripped.split(':');
      //console.log(split);
      var thisTime = (split[0] * 60) + parseInt(split[1]);
      console.log('thisHref is ' + thisHref + ' thisTime is ' + thisTime);
      videoJumpToTime(thisHref,thisTime)
  });

MathJax.Hub.Config({

  "HTML-CSS": {
      scale: 100
   }
});
 
}
</script></p></body></html>