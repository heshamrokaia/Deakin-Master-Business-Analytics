<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>SEBE Template</title>
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-fl.css">
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/open-source-css-and-js/prism/prism.css">
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/open-source-css-and-js/prism/prism.overrides.css">
</head>
<!-- ------------------------------------------- -->
<body class="cloudFirst">
<h1>Neural Network</h1>
<!-- ------------------------------------------- -->
<p></p>
<h2>Artificial Neural Network</h2>
<p>ANNs were originally attempts at modeling neurons in the brain to achieve human-like learning.&nbsp;Individual neurons were modeled with simple mathematical step functions (called&nbsp;<em>activation functions</em>), taking in weighted input from some neurons and emitting output to some other neurons if triggered. This mathematical model of a biological neuron is also called a&nbsp;<em>perceptron</em>. Armed with perceptrons, we then can form a plethora of different neural networks by varying the topology, activation functions, learning objectives, or training methods of the model.</p>
<p>Typically, ANNs are made up of neurons arranged in&nbsp;layers. Each neuron in a layer receives input from the previous layer and, if activated, emits output to one or more neurons in the next layer. Each connection of two neurons is associated with a&nbsp;weight, and each neuron or layer might also have an associated&nbsp;bias. These are the parameters to be trained by the process of&nbsp;backpropagation, which we describe simply and briefly. Before starting, all of the weights and biases are randomly initialized. For each sample in the training set, we perform two steps:</p>
<ul>
<li>Forward pass. Feed the input through the ANN and get the current prediction.</li>
<li>Backward pass. If the prediction is correct, reward the connections that produced this result by increasing their weights in proportion to the confidence of the prediction. If the prediction is wrong, penalize the connections that contributed to this wrong result.</li>
</ul>
<p></p>
<h2>Multilayer Perceptron&nbsp;</h2>
<p>A&nbsp;<b>multilayer perceptron</b>&nbsp;(MLP) is a class of feedforward <strong>artificial</strong>&nbsp;<b>neural network</b>&nbsp;(ANN).</p>
<p>The advantages of Multi-layer Perceptron are:</p>
<ul>
<li>Capability to learn non-linear models.</li>
<li>Capability to learn models in real-time (on-line learning)</li>
</ul>
<p>The disadvantages of Multi-layer Perceptron (MLP) include:</p>
<ul>
<li>MLP with hidden layers have a non-convex loss function where there exists more than one local minimum. Therefore different random weight initializations can lead to different validation accuracy.</li>
<li>MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.</li>
<li>MLP is sensitive to feature scaling.</li>
</ul>
<p></p>
<p>In recent years, with the development of GPUs (which has a powerful matrix and vector calculation computing capabilities), neural network training can be achievable in a shorter time and accessible to more people. Superior performance and solution accuracy is achieved with large number of multiple layers of neural networks, well known as <strong>deep neural network</strong> or <strong>deep learning</strong>. Research also opened a world of new applications. Deep Neural networks can learn from huge amounts of data and take advantage of big data.</p>
<p>See the following video to explore the working&nbsp;principles and capabilities of deep neural network.</p>
<p><iframe width="500" height="281" src="https://www.youtube.com/embed/6M5VXKLf4D4?feature=oembed&amp;wmode=opaque&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<h2><span style="color: #cf2a27;"><br /><br /></span></h2>
<h2>Neural Network based on Scikit-learn</h2>
<pre>clf = MLPClassifier(solver='lbfgs', alpha=1e-5,<br /> hidden_layer_sizes=(5, 2), random_state=1)<br />clf.fit(X_train, y_train)<br />y_pred = clf.predict(X_test)</pre>
<p></p>
<p><span style="color: #cf2a27;"></span></p>
<p><span style="color: #cf2a27;"></span></p>
</body>
<script defer type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-master.js"></script>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/open-source-css-and-js/prism/prism.js"></script>

<script  type="text/javascript">
function localFunction(){

  console.log("");
  console.log("ready!");

 
  /* ------------------------------------------------ */  
  /* -- START: PRISM JS PRINT LANGUAGES TO CONSOLE -- */
  var p = Prism.languages;
  var languagesArray = new Array();

  // iterate over elements in Prism.languages
  console.log("")
  console.log("Iterating over Prism.languages object...");
  for (var key in p) {
    if (p.hasOwnProperty(key)) {
      // if an element is a function, ignore it
      if ( p[key] instanceof Function ) {
        console.log("found function: " + key);
      } else {
        // otherwise if it's an object, count it as language
        languagesArray.push(key);
      }
    }
  }
  console.log("");

  var languagesString = "";
  var counter = 0;
  console.log("Found " + languagesArray.length + " languages in the Prism.languages object");
  languagesArray.sort().forEach(function (language) {
    languagesString += language;
    if(++counter < languagesArray.length) {
      languagesString += ", ";
    }
  });

  console.log("List of languages available:");
  console.log("--------------------------------------");
  console.log(languagesString);
  console.log("--------------------------------------");
  /* -- END:   PRISM JS PRINT LANGUAGES TO CONSOLE -- */
  /* ------------------------------------------------ */  

  $('#viewTranscript').click(function(){
    if($('#viewTranscript').text() == 'View transcript') {
      $('#transcript-en').show();
      $('#viewTranscript').text('Close transcript');
    } else {
      $('#transcript-en').hide();
      $('#viewTranscript').text('View transcript');
    }
  });
 
  /* Just need 3 things in the markup: 1. href="#video1", 2. class="transcript__timestamp" and 3. the timestamp value eg. 2:47  */
 $(".transcript__timestamp").click(function(){

    //collect video id and time attributes

      //var thisID = $(this).attr('id');
      var thisHref = $(this).attr('href');
      //the href is an id but will strp the # of it in case that's not always what the id is. Thsi hash can be added back oin the global func
      thisHref = thisHref.substring(1);
      //console.log(thisHref);
      var thisTimsStr = $(this).text();

      //thisTimsStr may have extra text after the actual time so to make sure, it needs to be stripped out.
      var n = thisTimsStr.indexOf(":")+3;
      var stripped = thisTimsStr.substring(0, n);
      //console.log('stripped '+ stripped);
      //now convert to seconds
      var split = stripped.split(':');
      //console.log(split);
      var thisTime = (split[0] * 60) + parseInt(split[1]);
      console.log('thisHref is ' + thisHref + ' thisTime is ' + thisTime);
      videoJumpToTime(thisHref,thisTime)
  });

MathJax.Hub.Config({

  "HTML-CSS": {
      scale: 100
   }
});
 
}
</script>
</html>