<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>SEBE Template</title>
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-fl.css">
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/open-source-css-and-js/prism/prism.css">
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/open-source-css-and-js/prism/prism.overrides.css">
</head>
<!-- ------------------------------------------- -->
<body class="cloudFirst">
<h1>Taxonomy of Adversarial Machine Learning</h1>
<!-- ------------------------------------------- -->
<h2><span style="color: #cf2a27;">&nbsp;</span></h2>
<p>A qualitative taxonomy of attacks against a machine learning system categorizes an attack based on the following three properties:</p>
<h2>Influence:</h2>
<p>This property explains the capability of an attacker.</p>
<h4><strong>Causative</strong></h4>
<p>Causative attacks alter the training process through influence over the training data. Because it is difficult for an adversary to manipulate an offline curated training set, this type of attack is predominately relevant to&nbsp;<i>online learners</i>. Online learners automatically adapt to changing data distributions by directly exploiting user interactions or feedback on predictions to update the trained model. By sacrificing stationarity for adaptability, such learning systems continuously evolve by incrementally training&nbsp;statistical models with freshly observed data. Typical use cases of online learning include an image classification service that learns from user corrections and reinforcement, or malicious traffic detection on websites that frequently experience viral traffic spikes.</p>
<p>&nbsp;</p>
<h4>Exploratory&nbsp;</h4>
<p>Exploratory attacks do not alter the training process but use other techniques, such as probing the detector, to discover information about it or its training data.</p>
<p><i>Exploratory attacks</i>&nbsp;are purely based on post&ndash;training phase interactions with machine learning systems.&nbsp;In this mode of attack, actors do not have any influence over the trained data manifold, but instead find and exploit adversarial space to cause models to make mistakes that they were not designed to make. A naive example of an exploratory attack is to engage in brute-force fuzzing of a machine learning classifier&rsquo;s input space to find samples that are wrongly&nbsp;classified.</p>
<p>&nbsp;</p>
<h2>Security violation</h2>
<p>Based on the three key properties of security requirements, attack taxonomy can be classified into three groups:</p>
<h4>Integrity attacks&nbsp;</h4>
<p><i>Integrity attacks</i>&nbsp;on machine learning systems affect only the ability of security detectors to find attacks; that is, they reduce the true positive rate (i.e., recall). A successful launch of such an attack on a machine learning web application firewall would mean that an adversary can successfully execute attacks that the firewall was specifically designed to detect. Integrity attacks result in intrusion points being classified as normal (false negatives).</p>
<h4></h4>
<h4>Availability attacks</h4>
<p><i>Availability attacks</i>, which are usually the result of indiscriminate attacks, degrade the usability of a system by reducing the true positive rate and increasing the false positive rate. When systems fail in this manner, it becomes difficult to reliably act on the results produced and hence the attack is viewed as a reduction in system availability. This type of attack is relevant only to causative attacks because it typically involves tampering with an (online) learning agent&rsquo;s decision functions.</p>
<p>Availability attacks cause so many classification errors, both false negatives and false positives, that the system becomes effectively unusable. It creates a denial of service event in which benign instances are incorrectly filtered as false positives (an availability violation).</p>
<p><strong></strong></p>
<p><strong>Privacy attacks&nbsp;</strong></p>
<p>Privacy - In a privacy violation, the adversary obtains information from the learner, compromising the secrecy or privacy of the system&rsquo;s users. In this type of attack, a security violation is caused using the filter&rsquo;s responses to infer confidential information used in the learning process (a privacy violation).</p>
<p>&nbsp;</p>
<h2>Specificity</h2>
<p>This property refers to how specific the attacker&rsquo;s intention is. Attacks on machine learning algorithms can be classified in two categories:</p>
<h4>Targeted Attacks</h4>
<p>It&nbsp;refer to attempts to cause a directed and intentional shift of a model&rsquo;s predictions to an alternate, focused outcome. For instance, a targeted attack of a malware family classifier could cause samples belonging to malware family A to be reliably misclassified as malware family B. In a targeted attack, the focus is on a single or small set of target points.</p>
<h4>Indiscriminate Attacks</h4>
<p>Indiscriminate - An indiscriminate adversary has a more flexible goal that involves a very general class of points, such as &ldquo;any false negative.&rdquo; These type of attacks&nbsp;are highly unspecific attacks by adversaries who want models to make wrong decisions but don&rsquo;t necessarily care what the eventual&nbsp;<span>outcome&nbsp;of the system is. An indiscriminate attack on the malware family classifier just mentioned would cause samples belonging to malware family A to be misclassified as&nbsp;<i>anything but</i>&nbsp;family A.</span></p>
<p><span></span></p>
<p><span></span></p>
<p><span></span></p>
<p></p>
</body>
<script defer type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-master.js"></script>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/open-source-css-and-js/prism/prism.js"></script>

<script  type="text/javascript">
function localFunction(){

  console.log("");
  console.log("ready!");

 
  /* ------------------------------------------------ */  
  /* -- START: PRISM JS PRINT LANGUAGES TO CONSOLE -- */
  var p = Prism.languages;
  var languagesArray = new Array();

  // iterate over elements in Prism.languages
  console.log("")
  console.log("Iterating over Prism.languages object...");
  for (var key in p) {
    if (p.hasOwnProperty(key)) {
      // if an element is a function, ignore it
      if ( p[key] instanceof Function ) {
        console.log("found function: " + key);
      } else {
        // otherwise if it's an object, count it as language
        languagesArray.push(key);
      }
    }
  }
  console.log("");

  var languagesString = "";
  var counter = 0;
  console.log("Found " + languagesArray.length + " languages in the Prism.languages object");
  languagesArray.sort().forEach(function (language) {
    languagesString += language;
    if(++counter < languagesArray.length) {
      languagesString += ", ";
    }
  });

  console.log("List of languages available:");
  console.log("--------------------------------------");
  console.log(languagesString);
  console.log("--------------------------------------");
  /* -- END:   PRISM JS PRINT LANGUAGES TO CONSOLE -- */
  /* ------------------------------------------------ */  

  $('#viewTranscript').click(function(){
    if($('#viewTranscript').text() == 'View transcript') {
      $('#transcript-en').show();
      $('#viewTranscript').text('Close transcript');
    } else {
      $('#transcript-en').hide();
      $('#viewTranscript').text('View transcript');
    }
  });
 
  /* Just need 3 things in the markup: 1. href="#video1", 2. class="transcript__timestamp" and 3. the timestamp value eg. 2:47  */
 $(".transcript__timestamp").click(function(){

    //collect video id and time attributes

      //var thisID = $(this).attr('id');
      var thisHref = $(this).attr('href');
      //the href is an id but will strp the # of it in case that's not always what the id is. Thsi hash can be added back oin the global func
      thisHref = thisHref.substring(1);
      //console.log(thisHref);
      var thisTimsStr = $(this).text();

      //thisTimsStr may have extra text after the actual time so to make sure, it needs to be stripped out.
      var n = thisTimsStr.indexOf(":")+3;
      var stripped = thisTimsStr.substring(0, n);
      //console.log('stripped '+ stripped);
      //now convert to seconds
      var split = stripped.split(':');
      //console.log(split);
      var thisTime = (split[0] * 60) + parseInt(split[1]);
      console.log('thisHref is ' + thisHref + ' thisTime is ' + thisTime);
      videoJumpToTime(thisHref,thisTime)
  });

MathJax.Hub.Config({

  "HTML-CSS": {
      scale: 100
   }
});
 
}
</script>
</html>