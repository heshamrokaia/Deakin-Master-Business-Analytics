<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager --><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager --><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>CloudDeakin Dual Delivery Template</title>
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-fl.css">
  <link rel="stylesheet" type="text/css" href="../00-assets/navbar/navbar-parent.css">
<link rel="stylesheet" type="text/css" href="../00-assets/css/sit307-720.css">

<link rel="stylesheet" href="https://s.brightspace.com/lib/fonts/0.5.0/fonts.css"></head><body class="cloudFirst"><p><img src="../images/Definition%20and%20Properties%20image%201.jpg" alt="Display computer server connections flashing Computer server connections and matrix coding" title="Display computer server connections flashing Computer server connections and matrix coding" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<address><a href="https://www.gettyimages.com.au" target="_blank" rel="noopener noreferrer">© Getty Images</a></address><hr>
<div>
<h1>Definition and Properties</h1>
</div>
<div>
<p>Measuring&nbsp;<em>similarity</em>&nbsp;or&nbsp;<em>distances</em>&nbsp;between different data points is fundamental to many machine learning algorithms. We will be looking at these issues this week.</p>
<p>These algorithms are used both in&nbsp;<em>supervised learning methods</em>&nbsp;and&nbsp;<em>unsupervised learning problems</em>. We will go through how to select a metric as we go through this week.</p>
<p>Depending on the nature of the data point, various measurements can be utilised to measure distance.</p>
<h3 id="distance-metrics">Distance metrics</h3>
<p>Distance metrics are used widely in machine learning algorithms. Distance measures are functions that define a distance&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>d</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d(x_i,x_j)\)"}</annotation></semantics></math>&nbsp;between any two data instances&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>x</mi><mi>i</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(x_i\)"}</annotation></semantics></math>&nbsp;and<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>x</mi><mi>j</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(x_j\)"}</annotation></semantics></math>&nbsp;</p>
<p>for measuring how similar the instances are.</p>
<p>The most related examples in machine learning are:</p>
<ul>
<li>clustering algorithms (we looked at examples of clustering last week)</li>
<li>K-Nearest-Neighbor</li>
<li>Support Vector Machines (SVM)</li>
<li>data visualization</li>
<li>information retrieval</li>
<li>ranking</li>
</ul>
<p>Distance measures satisfy the following three properties:</p>
<ol>
<li>For any instance <math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>x</mi><mi>i</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(x_i\)"}</annotation></semantics></math>,&nbsp;distance with itself is&nbsp;<em>zero</em>. That is,&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>d</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d(x_i,x_i)=0\)"}</annotation></semantics></math>.</li>
<li>For an instance pairs&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>x</mi><mi>i</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(x_i\)"}</annotation></semantics></math>&nbsp;and&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>x</mi><mi>j</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(x_j\)"}</annotation></semantics></math>,&nbsp;the distance is&nbsp;<em>non-negative</em>&nbsp;and&nbsp;<em>symmetric</em>. That is,&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>d</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>≥<!-- ≥ --></mo><mn>0</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d(x_i,x_j) \geq 0\)"}</annotation></semantics></math>&nbsp;and&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>d</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>d</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo>,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d(x_i,x_j) = d(x_j,x_i)\)"}</annotation></semantics></math>.</li>
<li>Distance measure follows&nbsp;<em>triangular inequality</em>. That is,&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>d</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo>≤<!-- ≤ --></mo><mi>d</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>d</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo>,</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d(x_i,x_k) \leq d(x_i,x_j)+d(x_j,x_k)\)"}</annotation></semantics></math>.</li>
</ol>
<span style="font-family: Lato, Arial, sans-serif; font-size: 0.95rem;">Distance measures satisfying above properties are also known as&nbsp;</span><em style="font-family: Lato, Arial, sans-serif; font-size: 0.95rem;">Distance Metrics</em><span style="font-family: Lato, Arial, sans-serif; font-size: 0.95rem;">. Now let us work on two examples.</span></div>
<div><br>
<h4 id="example-1-nearest-neighbor-classification" style="display: inline !important;">Example 1: Nearest Neighbor Classification</h4>
<p class="centerImage"><img src="../images/Definition%20and%20Properties%20image%202.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5 id="figure-using-distance-to-find-the-label-of-the-new-data-point-the-red-triangle">Figure. Using distance to find the label of the new data point (the red triangle).</h5>
<p>We can use the distance to find the nearest neghbour and classify the data to the class label of this neighbour. So what do you think is the correct label of the red triangle in the Figure? Square or circle?</p>
<h4 id="example-2-image-retrieval">Example 2: Image retrieval</h4>
<p>Another interesting example is in image retrieval. Consider the&nbsp;<em>NUS Wide Animal dataset</em>, which contains&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mn>269</mn><mo>,</mo><mn>648</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(269,648\)"}</annotation></semantics></math>&nbsp;images of 13 animal types.</p>
<p class="centerImage"><img src="../images/Definition%20and%20Properties%20image%203.png" alt="" title="" style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<h5 id="figure-animal-types-in-nus-wide-animal-dataset">Figure. Animal types in NUS Wide Animal dataset.</h5>
<p>Now, given a new image like the image of a cat, can we fetch all cat images from the dataset? Apparently yes! with the help of distance measurements this is possible.</p>
<h3 id="types-of-distance-measurements">Types of distance measurements</h3>
<p>Distance measurements are very important in machine learning problems. Let’s look at different types of distance measurements.</p>
<h4 id="euclidean-distance">Euclidean distance</h4>
<p>Euclidean distance is the&nbsp;<em>ordinary</em>&nbsp;straight-line distance between two points in Euclidean (everyday) space. For any two data instances, represented by&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>d</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d\)"}</annotation></semantics></math>-dimensional feature vectors&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_i,\textbf{x}_j\)"}</annotation></semantics></math>&nbsp;their Euclidean distance is computed as:&nbsp;</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><msub><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mi>E</mi><mi>u</mi><mi>c</mi><mi>l</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>a</mi><mi>n</mi></mrow></msub><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mo maxsize="1.2em" minsize="1.2em">(</mo></mrow><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>,</mo><mn>1</mn></mrow></msub><mo>−<!-- − --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mrow class="MJX-TeXAtom-ORD"><mi>j</mi><mo>,</mo><mn>1</mn></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>,</mo><mi>D</mi></mrow></msub><mo>−<!-- − --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mrow class="MJX-TeXAtom-ORD"><mi>j</mi><mo>,</mo><mi>D</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><msup><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"d_{Euclidean}(\textbf{x}_i,\textbf{x}_j) = \big ( (\textbf{x}_{i,1} - \textbf{x}_{j,1})^2+...+(\textbf{x}_{i,D} - \textbf{x}_{j,D})^2)^{\frac{1}{2}}"}</annotation></semantics></math></p>
<p>For example, consider these two vectors:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mn>1</mn></msub><mo>=</mo><msup><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd></mtr></mtable><mo>]</mo></mrow><mi>T</mi></msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">d</mi></mrow><mspace width="1em"></mspace><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mn>2</mn></msub><mo>=</mo><msup><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr></mtable><mo>]</mo></mrow><mi>T</mi></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\textbf{x}_1 = \begin{bmatrix} 1\\ 1\\ 2\\ 1\\ 0 \end{bmatrix}^T \mathrm{and}\quad \textbf{x}_2 = \begin{bmatrix} 0\\ 2\\ 2\\ 0\\ 2 \end{bmatrix}^T"}</annotation></semantics></math></p>
<p>We can calculate the distance as:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><mo>=</mo><msqrt><mo stretchy="false">(</mo><mn>1</mn><mo>−<!-- − --></mo><mn>0</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−<!-- − --></mo><mn>2</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>2</mn><mo>−<!-- − --></mo><mn>2</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−<!-- − --></mo><mn>0</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>0</mn><mo>−<!-- − --></mo><mn>2</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup></msqrt></mstyle><annotation encoding="latex">{"version":"1.1","math":"=\sqrt{(1-0)^2+(1-2)^2+(2-2)^2+(1-0)^2+(0-2)^2}"}</annotation></semantics></math></p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><mo>=</mo><msqrt><mn>1</mn><mo>+</mo><mn>1</mn><mo>+</mo><mn>0</mn><mo>+</mo><mn>1</mn><mo>+</mo><mn>4</mn></msqrt></mstyle><annotation encoding="latex">{"version":"1.1","math":"=\sqrt{1+1+0+1+4}"}</annotation></semantics></math></p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><mo>=</mo><msqrt><mn>7</mn></msqrt><mo>≈<!-- ≈ --></mo><mn>2.65</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"= \sqrt{7} \approx 2.65"}</annotation></semantics></math></p>
<h4 id="cosine-distance">Cosine distance</h4>
<p>We previously introduced&nbsp;<em>cosine distance</em>&nbsp;in course 1. But as a reminder, we define Cosine distance for any two data instance represented by<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>d</mi><mo>−<!-- − --></mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d-\)"}</annotation></semantics></math>&nbsp;dimensional feature vectors&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_i,\textbf{x}_j\)"}</annotation></semantics></math>.&nbsp;&nbsp;The Cosine distance for these two feature vectors are computed as:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mi>C</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−<!-- − --></mo><mfrac><mrow><msubsup><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi><mi>T</mi></msubsup><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub></mrow><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mn>2</mn></msub><mo>.</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mn>2</mn></msub></mrow></mfrac></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d_{Cosine}(\textbf{x}_i,\textbf{x}_j) = 1-\frac{\textbf{x}_i^T \textbf{x}_j}{||\textbf{x}_i||_2.||\textbf{x}_j||_2}\)"}</annotation></semantics></math></p>
<p>Lets see an example:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mn>1</mn></msub><mo>=</mo><msup><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd></mtr></mtable><mo>]</mo></mrow><mi>T</mi></msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">d</mi></mrow><mspace width="1em"></mspace><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mn>2</mn></msub><mo>=</mo><msup><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr></mtable><mo>]</mo></mrow><mi>T</mi></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\textbf{x}_1 = \begin{bmatrix} 1\\ 1\\ 2\\ 1\\ 0 \end{bmatrix}^T \mathrm{and}\quad \textbf{x}_2 = \begin{bmatrix} 0\\ 2\\ 2\\ 0\\ 2 \end{bmatrix}^T"}</annotation></semantics></math></p>
<p>We can calculate the&nbsp;<em>cosine distance</em>&nbsp;as:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><mo>=</mo><mn>1</mn><mo>−<!-- − --></mo><mfrac><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>×<!-- × --></mo><mn>0</mn><mo>+</mo><mn>1</mn><mo>×<!-- × --></mo><mn>2</mn><mo>+</mo><mn>2</mn><mo>×<!-- × --></mo><mn>2</mn><mo>+</mo><mn>1</mn><mo>×<!-- × --></mo><mn>0</mn><mo>+</mo><mn>0</mn><mo>×<!-- × --></mo><mn>2</mn><mo stretchy="false">)</mo></mrow><mrow><msqrt><mo stretchy="false">(</mo><msup><mn>1</mn><mn>2</mn></msup><mo>+</mo><msup><mn>1</mn><mn>2</mn></msup><mo>+</mo><msup><mn>2</mn><mn>2</mn></msup><mo>+</mo><msup><mn>1</mn><mn>2</mn></msup><mo>+</mo><msup><mn>0</mn><mn>2</mn></msup><mo stretchy="false">)</mo></msqrt><mo>×<!-- × --></mo><msqrt><mo stretchy="false">(</mo><msup><mn>0</mn><mn>2</mn></msup><mo>+</mo><msup><mn>2</mn><mn>2</mn></msup><mo>+</mo><msup><mn>2</mn><mn>2</mn></msup><mo>+</mo><msup><mn>0</mn><mn>2</mn></msup><mo>+</mo><msup><mn>2</mn><mn>2</mn></msup><mo stretchy="false">)</mo></msqrt></mrow></mfrac></mstyle><annotation encoding="latex">{"version":"1.1","math":"= 1 - \frac{(1\times0+1\times2+2\times2+1\times0+0\times2)} {\sqrt{(1^2+1^2+2^2+1^2+0^2)}\times \sqrt{(0^2+2^2+2^2+0^2+2^2)}}"}</annotation></semantics></math></p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><mo>=</mo><mn>0.3453</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"=0.3453"}</annotation></semantics></math></p>
<h4 id="mahalanobis-distance">Mahalanobis distance</h4>
<p>The Mahalanobis distance (MD) is the distance between two points in multivariate space. For any two data instances, represented by&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>d</mi><mo>−<!-- − --></mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d-\)"}</annotation></semantics></math>&nbsp;dimensional feature vectors&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_i,\textbf{x}_j\)"}</annotation></semantics></math>&nbsp;their Mahalanobis distance is computed as:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><msub><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mi>M</mi><mi>a</mi><mi>h</mi><mi>a</mi><mi>l</mi><mi>a</mi><mi>n</mi><mi>o</mi><mi>b</mi><mi>i</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>−<!-- − --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><msup><mi>M</mi><mrow class="MJX-TeXAtom-ORD"><mo>−<!-- − --></mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>−<!-- − --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"d_{Mahalanobis}(\textbf{x}_i,\textbf{x}_j) = (\textbf{x}_i-\textbf{x}_j)M^{-1}(\textbf{x}_i-\textbf{x}_j)^T"}</annotation></semantics></math></p>
<p>Where&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>M</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(M\)"}</annotation></semantics></math>&nbsp;is the covariance matrix of the data. Intuitively, the covariance matrix generalizes the notion of variance to multiple dimensions. In other words, the elements of covariance matrix in the&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>i</mi><mo>,</mo><mi>j</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(i,j\)"}</annotation></semantics></math>&nbsp;position is the covariance between the&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>i</mi><mo>−<!-- − --></mo><mi>t</mi><mi>h</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(i-th\)"}</annotation></semantics></math>&nbsp;and<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>j</mi><mo>−<!-- − --></mo><mi>t</mi><mi>h</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(j-th\)"}</annotation></semantics></math>&nbsp;elements of a vector. We will later explain covariance matrix in more detail.</p>
<p>Mahalanobis distance can be thought of scaling each data dimension by its variance and adjusting for their relationships. When data are independent, i.e.&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>M</mi><mo>=</mo><mi>I</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(M=I\)"}</annotation></semantics></math>&nbsp;(identity matrix), Mahalanobis distance becomes same as Euclidean distance.</p>
<h4 id="cityblockmanhattan-distance">Cityblock/Manhattan distance</h4>
<p>For any two data instances, represented by&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>d</mi><mo>−<!-- − --></mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(d-\)"}</annotation></semantics></math>&nbsp;dimensional feature vectors&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_i,\textbf{x}_j\)"}</annotation></semantics></math>,&nbsp;their Cityblock distance is computed as:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><msub><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mi>C</mi><mi>i</mi><mi>t</mi><mi>y</mi><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi></mrow></msub><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>,</mo><mn>1</mn></mrow></msub><mo>−<!-- − --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mrow class="MJX-TeXAtom-ORD"><mi>j</mi><mo>,</mo><mn>1</mn></mrow></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>,</mo><mi>D</mi></mrow></msub><mo>−<!-- − --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mrow class="MJX-TeXAtom-ORD"><mi>j</mi><mo>,</mo><mi>D</mi></mrow></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mstyle><annotation encoding="latex">{"version":"1.1","math":"d_{Cityblock}(\textbf{x}_i,\textbf{x}_j) = |\textbf{x}_{i,1} - \textbf{x}_{j,1}|+...+|\textbf{x}_{i,D} - \textbf{x}_{j,D}|"}</annotation></semantics></math></p>
<p>In most cases, this distance measure yields results similar to the Euclidean distance. However, using City block distance, the effect of a large difference in a single dimension is dampened (since the distances are not squared).</p>
<p>Let us compute the Cityblock/Manhattan Distance for two sample vectors:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mn>1</mn></msub><mo>=</mo><msup><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd></mtr></mtable><mo>]</mo></mrow><mi>T</mi></msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">d</mi></mrow><mspace width="1em"></mspace><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mn>2</mn></msub><mo>=</mo><msup><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd></mtr></mtable><mo>]</mo></mrow><mi>T</mi></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_1 = \begin{bmatrix} 1\\ 1\\ 2\\ 1\\ 0 \end{bmatrix}^T \mathrm{and}\quad \textbf{x}_2 = \begin{bmatrix} 0\\ 2\\ 2\\ 0\\ 2 \end{bmatrix}^T\)"}</annotation></semantics></math></p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><mi>C</mi><mi>i</mi><mi>t</mi><mi>y</mi><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mtext>&nbsp;</mtext><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mn>1</mn><mo>−<!-- − --></mo><mn>0</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mo>+</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mn>1</mn><mo>−<!-- − --></mo><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mo>+</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mn>2</mn><mo>−<!-- − --></mo><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mo>+</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mn>1</mn><mo>−<!-- − --></mo><mn>0</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mo>+</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mn>0</mn><mo>−<!-- − --></mo><mn>2</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mo>=</mo><mn>5</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"Cityblock\ distance = |1-0|+|1-2|+|2-2|+|1-0|+|0-2| = 5"}</annotation></semantics></math></p>
<h4 id="minkowski-distance">Minkowski distance</h4>
<p>The Minkowski distance defines a distance between two points in a normed vector space. Think of Euclidean distance (2 norm of&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>−<!-- − --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_i-\textbf{x}_j\)"}</annotation></semantics></math>)&nbsp;and Cityblock distance as (1 norm of&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>−<!-- − --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_i - \textbf{x}_i\)"}</annotation></semantics></math>)&nbsp;Minkowski distance is a generalization of these distances defined for any&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>p</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(p\)"}</annotation></semantics></math>-norm.</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><mi>d</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">y</mtext></mrow><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><munderover><mo>∑<!-- ∑ --></mo><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>n</mi><mo>−<!-- − --></mo><mn>1</mn></mrow></munderover><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−<!-- − --></mo><msub><mi>y</mi><mi>i</mi></msub><msup><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>p</mi></msup><msup><mo stretchy="false">)</mo><mfrac><mn>1</mn><mi>p</mi></mfrac></msup></mstyle><annotation encoding="latex">{"version":"1.1","math":"d(\textbf{x},\textbf{y}) = (\sum_{i=0}^{n-1} |x_i - y_i|^p)^\frac{1}{p}"}</annotation></semantics></math></p>
<ul>
<li>When&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>p</mi><mo>=</mo><mn>1</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(p=1\)"}</annotation></semantics></math>, the distance is known as the Manhattan distance.</li>
<li><span style="font-family: Lato, sans-serif; font-size: 0.95rem;">When&nbsp;</span><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>p</mi><mo>=</mo><mn>2</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(p=2\)"}</annotation></semantics></math><span style="font-family: Lato, sans-serif; font-size: 0.95rem;">&nbsp;the distance is known as the Euclidean distance.</span></li>
</ul>
<p>Reminder: If you do not clearly remember the definition of norm, you may want to have a review of&nbsp;weeks 1 and 2.</p>
<h4 id="jaccard-distance">Jaccard distance</h4>
<p>Note: there was a small error in this equation that has been fixed.</p>
<p>The Jaccard distance is a distance used to measure diversity of any two sets. Consider any two instances&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_i\)"}</annotation></semantics></math>&nbsp;and<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_j\)"}</annotation></semantics></math>&nbsp;as binary vectors indicating presence or absence of features.&nbsp;Jaccard distance between&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_i\)"}</annotation></semantics></math>&nbsp;and&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_j\)"}</annotation></semantics></math>&nbsp;is defined as:</p>
<p class="note2" style="font-size: 0.95rem;"><span style="font-size: 15.2px;"><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><msub><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mi>J</mi><mi>a</mi><mi>c</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>d</mi></mrow></msub><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−<!-- − --></mo><mfrac><mrow><mo fence="false" stretchy="false">∣<!-- ∣ --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>∩<!-- ∩ --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><msub><mo fence="false" stretchy="false">∣<!-- ∣ --></mo><mn>1</mn></msub></mrow><mrow><mo fence="false" stretchy="false">∣<!-- ∣ --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>∪<!-- ∪ --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mi>r</mi><msub><mo fence="false" stretchy="false">|</mo><mn>1</mn></msub></mrow></mfrac></mstyle><annotation encoding="latex">{"version":"1.1","math":"d_{Jaccard}(\textbf{x}_i,\textbf{x}_j) = 1 - \frac{\lvert\textbf{x}_i \cap \textbf{x}_j\rvert_1}{\lvert\textbf{x}_i \cup \textbf{x}_jr\vert_1}"}</annotation></semantics></math></span></p>
</div>
<p><span style="font-size: 15.2px;"><span style="font-size: 15.2px;">Where&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo>∩<!-- ∩ --></mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\cap\)"}</annotation></semantics></math>&nbsp;denotes logical&nbsp;<em>and</em>&nbsp;while&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo>∪<!-- ∪ --></mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\cup\)"}</annotation></semantics></math>&nbsp;denotes logical&nbsp;<em>or</em>&nbsp;operators. The&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo fence="false" stretchy="false">∣<!-- ∣ --></mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><msub><mo fence="false" stretchy="false">∣<!-- ∣ --></mo><mn>1</mn></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\lvert\textbf{x}\rvert_1\)"}</annotation></semantics></math>&nbsp;</span></span>is 1-norm.</p>
<p>Let us assume that&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">[</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_i = [1,0,1]\)"}</annotation></semantics></math>&nbsp;and&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mo>=</mo><mo stretchy="false">[</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo stretchy="false">]</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\textbf{x}_j = [1,1,0]\)"}</annotation></semantics></math>,&nbsp;the Jaccard distance calculated as:&nbsp;</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><msub><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mi>J</mi><mi>a</mi><mi>c</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>d</mi></mrow></msub><mo stretchy="false">(</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>,</mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−<!-- − --></mo><mfrac><mn>1</mn><mn>3</mn></mfrac><mo>=</mo><mfrac><mn>2</mn><mn>3</mn></mfrac></mstyle><annotation encoding="latex">{"version":"1.1","math":"d_{Jaccard}(\textbf{x}_i,\textbf{x}_j) = 1 - \frac{1}{3} = \frac{2}{3}"}</annotation></semantics></math></p>
<p>Note that:</p>
<p><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo fence="false" stretchy="false">∣<!-- ∣ --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>∩<!-- ∩ --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><msub><mo>∣<!-- ∣ --></mo><mn>1</mn></msub><mo>=</mo><mo>∣<!-- ∣ --></mo><mo stretchy="false">[</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">1</mtext></mrow><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mtext class="MJX-tex-mathit" mathvariant="italic">0</mtext></mrow><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mtext class="MJX-tex-mathit" mathvariant="italic">1</mtext></mrow><mo stretchy="false">]</mo><mo>∩<!-- ∩ --></mo><mo stretchy="false">[</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">1</mtext></mrow><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mtext class="MJX-tex-mathit" mathvariant="italic">1</mtext></mrow><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mtext class="MJX-tex-mathit" mathvariant="italic">0</mtext></mrow><mo stretchy="false">]</mo><msub><mo>∣<!-- ∣ --></mo><mn>1</mn></msub><mo>=</mo><mo>∣<!-- ∣ --></mo><mo stretchy="false">[</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy="false">]</mo><msub><mo>∣<!-- ∣ --></mo><mn>1</mn></msub><mo>=</mo><mn>1</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\lvert\textbf{x}_i \cap \textbf{x}_j\rvert_1 = \lvert[\textbf{1},\textit{0},\textit{1}] \cap [\textbf{1},\textit{1},\textit{0}]\rvert_1 = \lvert[1,0,0] \rvert_1 = 1\)"}</annotation></semantics></math>&nbsp;and&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mo fence="false" stretchy="false">∣<!-- ∣ --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>i</mi></msub><mo>∪<!-- ∪ --></mo><msub><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">x</mtext></mrow><mi>j</mi></msub><msub><mo>∣<!-- ∣ --></mo><mn>1</mn></msub><mo>=</mo><mo>∣<!-- ∣ --></mo><mo stretchy="false">[</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">1</mtext></mrow><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">0</mtext></mrow><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">1</mtext></mrow><mo stretchy="false">]</mo><mo>∪<!-- ∪ --></mo><mo stretchy="false">[</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">1</mtext></mrow><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">1</mtext></mrow><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mtext mathvariant="bold">0</mtext></mrow><mo stretchy="false">]</mo><msub><mo>∣<!-- ∣ --></mo><mn>1</mn></msub><mo>=</mo><mo fence="false" stretchy="false">|</mo><mo stretchy="false">[</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo><msub><mo>∣<!-- ∣ --></mo><mn>1</mn></msub><mo>=</mo><mn>3</mn></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\lvert\textbf{x}_i \cup \textbf{x}_j\rvert_1 = \lvert[\textbf{1},\textbf{0},\textbf{1}] \cup [\textbf{1},\textbf{1},\textbf{0}]\rvert_1 = \vert[1,1,1] \rvert_1 = 3\)"}</annotation></semantics></math></p>
<p>In the next section we will show you some examples of different distance measures and their usage.</p>
<p></p>
<hr>
<div><iframe class="quickNavStyle" scrolling="no" src="../00-assets/navbar/navbar.html" title="NavBar" allowfullscreen="allowfullscreen" frameborder="0"></iframe></div>
<!-- <div style="padding-top: 20px;"><a href="#" class="navrep-button" target="_parent" title="Previous" style="padding: .5rem .5rem; font-size: 12pt; float: left;"> &lt; Previous</a> <a href="#" class="navrep-button" target="_parent" title="Next" style="padding: .5rem .5rem; font-size: 12pt; float: right;">Next &gt;</a></div>
<p style="padding-bottom: 50px;"></p>
</div> -->
<p>
<script defer="defer" type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-master.js"></script>
</p>
<p>
<script>
function localProc(){
  console.log("ready!");
}
</script>
</p>
<p>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-sebe-lst-learning-design/fl-dual-delivery/js/sebe-fl-nav.js"></script>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-sebe-lst-learning-design/fl-dual-delivery/js/sebe-fl.js"></script>
<script src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/jquery/jquery_3_5_1/jquery-3.5.1.min.js"></script>
<script src="../00-assets/navbar/navbar-parent.js"></script>
<script src="../00-assets/js/sit307-720.js"></script>
</p></body></html>