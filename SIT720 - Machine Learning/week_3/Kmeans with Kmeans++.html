<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager --><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager --><!-- Google Tag Manager --><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({'cmsType' : 'D2L'});</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-N3CB');</script><!-- End Google Tag Manager -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>CloudDeakin Dual Delivery Template</title>
<link rel="stylesheet" type="text/css" href="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-fl.css">
  <link rel="stylesheet" type="text/css" href="../00-assets/navbar/navbar-parent.css">
<link rel="stylesheet" type="text/css" href="../00-assets/css/sit307-720.css">

<link rel="stylesheet" href="https://s.brightspace.com/lib/fonts/0.5.0/fonts.css"></head><body style="color: rgb(32, 33, 34); font-family: verdana, sans-serif; font-size: 10px;"><p><img src="../images/Kmeans%20with%20Kmeans%2B%2B%20image%201.jpg" alt="Close-up of Millennium Bridge in Salford, Manchester Footbridge over the Manchester Ship Canal." title="Close-up of Millennium Bridge in Salford, Manchester Footbridge over the Manchester Ship Canal." style="max-width: 100%;" data-d2l-editor-default-img-style="true"></p>
<address><a href="https://www.gettyimages.com.au" target="_blank" rel="noopener noreferrer">© Getty Images</a></address>
<div>
<h1>Kmeans with Kmeans++</h1>
</div>
<div>
<p>Kmeans++ is an algorithm for choosing the initial cluster’s centre values or centroids for the Kmeans clustering algorithm.</p>
<p>As we have said before, K-means starts with allocating cluster centres randomly and then looks for&nbsp;<em>better</em>&nbsp;solutions. K-means++ starts with allocating one cluster centre randomly and then searches for other centres given the first one. So both algorithms use random initialisation as a starting point but in different ways. So Kmeans++:</p>
<ul>
<li>Chooses one centroid&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>μ<!-- μ --></mi><mn>1</mn></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\mu_1\)"}</annotation></semantics></math>&nbsp;</li>
<li>uniformly at random from the dataset</li>
<li>Let&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(D(x)\)"}</annotation></semantics></math>&nbsp;be the shortest distance from a data point to the closest centroid we have already chosen.</li>
<li>Choose a new centroid from the dataset with probability of&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mfrac><mrow><msup><mi>D</mi><mn>2</mn></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><munder><mo>∑<!-- ∑ --></mo><mrow class="MJX-TeXAtom-ORD"><mi>i</mi></mrow></munder><msup><mi>D</mi><mn>2</mn></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\frac{D^2(x_i)}{\sum_{i} D^2(x_i)}\)"}</annotation></semantics></math></li>
</ul>
<span style="font-family: Lato, sans-serif; font-size: 0.95rem;">Now repeat the previous step until we have initialised&nbsp;</span><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mi>K</mi></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(K\)"}</annotation></semantics></math><span style="font-family: Lato, sans-serif; font-size: 0.95rem;">&nbsp;centroids</span><br style="font-size: 0.95rem;">
<p>For further understanding of Kmeans you can read the article <a href="https://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf" target="_blank" rel="noopener noreferrer" title="">k-means++: The Advantages of Careful Seeding</a>&nbsp;by Arther and Vassilviskii.</p>
<h3 id="guarantee-of-kmeans">Guarantee of Kmeans++</h3>
<ul>
<li><span style="font-family: Lato, sans-serif; font-size: 0.95rem;">In a Kmeans algorithm with a random starting number of centroids, the objective function&nbsp;</span><strong style="font-family: Lato, sans-serif; font-size: 0.95rem;">monotonically decreases</strong><span style="font-family: Lato, sans-serif; font-size: 0.95rem;">&nbsp;with each iteration of the algorithm. In other words every time the algorithm runs, it gets closer to (and not further away from) the best solution.</span></li>
<li>Let us say, for the best solution, the objective function takes value&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>j</mi><mrow class="MJX-TeXAtom-ORD"><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>u</mi><mi>m</mi></mrow></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(j_{optimum}\)"}</annotation></semantics></math></li>
<li>Let us say, when using Kmeans the objective function converges to&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><msub><mi>j</mi><mrow class="MJX-TeXAtom-ORD"><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>d</mi></mrow></msub></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(j_{converged}\)"}</annotation></semantics></math></li>
</ul>
<span style="font-size: 15.2px;">Although there is no theoretical bound on&nbsp;<math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><semantics><mstyle><mfrac><msub><mi>j</mi><mrow class="MJX-TeXAtom-ORD"><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>d</mi></mrow></msub><msub><mi>j</mi><mrow class="MJX-TeXAtom-ORD"><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>u</mi><mi>m</mi></mrow></msub></mfrac></mstyle><annotation encoding="latex">{"version":"1.1","math":"\(\frac{j_{converged}}{j_{optimum}}\)"}</annotation></semantics></math>&nbsp;for Kmeans with random initialisation, Kmeans++ initialisation has the following theoretical guarantee on convergence:&nbsp;</span></div>
<div><span style="font-size: 15.2px;"><math title="" xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mstyle><mfrac><mrow><mi>E</mi><mo stretchy="false">(</mo><msub><mi>J</mi><mrow class="MJX-TeXAtom-ORD"><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo></mrow><msub><mi>J</mi><mrow class="MJX-TeXAtom-ORD"><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>u</mi><mi>m</mi></mrow></msub></mfrac><mo>≤<!-- ≤ --></mo><mn>8</mn><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>K</mi><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo></mstyle><annotation encoding="latex">{"version":"1.1","math":"\frac{E(J_{converged})}{J_{optimum}} \leq 8(logK+2)"}</annotation></semantics></math></span></div>
<div>
<p></p>
</div>
<hr>
<div><iframe class="quickNavStyle" scrolling="no" src="../00-assets/navbar/navbar.html" title="NavBar" allowfullscreen="allowfullscreen" frameborder="0"></iframe></div>
<!-- <div style="padding-top: 20px;"><a href="#" class="navrep-button" target="_parent" title="Previous" style="padding: .5rem .5rem; font-size: 12pt; float: left;"> &lt; Previous</a> <a href="#" class="navrep-button" target="_parent" title="Next" style="padding: .5rem .5rem; font-size: 12pt; float: right;">Next &gt;</a></div>
<p style="padding-bottom: 50px;"></p>
</div> -->
<p>
<script defer="defer" type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/templates/sebe-master.js"></script>
</p>
<p><script>
function localProc(){
  console.log("ready!");
}
</script></p>
<p>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-sebe-lst-learning-design/fl-dual-delivery/js/sebe-fl-nav.js"></script>
<script type="text/javascript" src="/content/enforced/384049-SEBE_LST_01/z-sebe-lst-learning-design/fl-dual-delivery/js/sebe-fl.js"></script>
<script src="/content/enforced/384049-SEBE_LST_01/z-intmedia-donotedit/jquery/jquery_3_5_1/jquery-3.5.1.min.js"></script>
<script src="../00-assets/navbar/navbar-parent.js"></script>
<script src="../00-assets/js/sit307-720.js"></script>
</p></body></html>